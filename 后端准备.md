[TOC]

# 操作系统

## 进程、线程、协程

**进程：** 进程是一个具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统**资源分配和独立运行的最小单位**。

**线程：** 线程是进程的一个执行单元，是**任务调度和系统执行的最小单位**。

**协程：** 协程是一种**用户态的轻量级线程**，协程的调度完全由用户控制。



#### 进程、线程、协程的区别【4】

线程与进程的比较：

- 进程是操作系统资源分配和独立运行的最小单位；线程是任务调度和系统执行的最小单位；
- 每个进程有独立的代码和数据空间，而线程只独享必不可少的资源，如寄存器和栈；
- 进程占据独立的内存，所以上下文进程间的切换开销比较大；线程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据



线程和协程的区别：

- 内存开销：创建一个协程需要2kb，栈空间不够会自动扩容， 创建一个线程需要1M空间。 
- 创建和销毁：创建线程是和操作系统打交道，内核态开销更大， 协程是由runtime管理，属于用户态，开销小。
- 切换成本：线程切换需要保存各种寄存器；协程保存的寄存器比较少，它能执行更多的指令。基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。



#### ⚠️什么时候用线程，什么时候用协程【1】





#### ⚠️共享内存的实现方式【1】





### 进程

####  进程状态【2】

在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wsycw76wj31fe0hy402.jpg" alt="截屏2022-11-07 19.46.47" style="zoom:33%;" />

在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。

挂起状态可以分为两种：

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wt4wmlp9j31bg0u0mzr.jpg" alt="截屏2022-11-07 19.53.04" style="zoom:33%;" />



#### 进程间通信【2】

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

**管道、消息队列、共享内存、信号量、套接字**

- 管道

  管道传输数据是单向的。A进程将数据以字节流写入管道，B进程需要等待A进程将信息写完以后才能读出来。

  比如 ps -f | grep xxx

  缺点：效率低，不适合进程间频繁地交换数据

- 消息队列

  在发送数据时，按照一个个独立单元发送，发送方和接收方约定好消息的类型和格式

  缺点：不适合比较大数据的传输；存在用户态与内核态之间的数据拷贝开销

- 共享内存

  申请一块虚拟地址空间，不同进程通过这块虚拟地址空间映射到相同的物理地址空间。无需拷贝。

  缺点：会出现冲突

- 信号量

  防止多进程竞争共享资源，而造成的数据错乱的一个约束和保护机制。使得共享的资源，在任意时刻只能被一个进程访问。

  信号量表示资源的数量，控制信号量的方式有两种原子操作：P 操作和 V 操作。P 操作为申请资源，V 操作是归还资源。

  信号初始化为 1，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问；信号初始化为 0，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行

- 信号

  信号是进程间通信机制中唯一的**异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，就有下面这几种，用户进程对信号的处理方式：

  - 执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。
  - 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。
  - 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程

- 套接字

  跨网络与不同主机上的进程之间通信

  domain 参数用来指定协议族、type 参数用来指定通信特性、protocal 参数原本是用来指定通信协议的（废弃）

  - TCP 协议通信的 socket 编程模型

    服务端和客户端初始化 socket -> 服务端 bind 绑定 IP 和端口 -> 服务端调用 listen 监听 -> 服务端调用 accept 等待客户端连接 -> 客户端调用 connect 发起连接请求 -> **服务端 accept 返回用于传输 socket 的文件描述符** -> 客户端 write 服务端read 

  - UDP 协议通信的 socket 编程模型

    只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind

  - 本地进程间通信的 socket 编程模型

    本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别



#### 进程调度算法【1】

- 先来先服务调度算法

  每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

- 最短作业优先调度算法

  ```
  优先把短作业执行完，再执行长作业。缺点是如果短作业很多，长作业会被搁置。
  ```

  优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

- 高响应比优先调度算法

  ```
  是在短作业优先的基础上改进，加上一个随时间叠加的权重。等待时间越长，权重越高。
  这种算法既可以优先完成短作业，又能确保长作业不会长期饥饿。
  ```

  每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wtlcdnq5j314w0bqmy7.jpg" alt="截屏2022-11-07 20.08.52" style="zoom:25%;" />

  （高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的）

- 时间片轮转调度算法

  ```
  定义一个时间片长度，平均给每个进程分配时间片，一旦时间片用完，作业就会由进行转为就绪，等待重新被调度。缺点是如果作业比较多，那长作业可能需要好几轮才可以被执行完。
  ```

  每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。

  - 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；
  - 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

- 最高优先级调度算法

  从就绪队列中选择最高优先级的进程进行运行。

  进程的优先级可以分为，静态优先级和动态优先级：

  - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
  - 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。

- 多级反馈队列调度算法

  ```
  设置了不同的队列，可以分类为高、中、低优先级。优先级越高，分配的时间片越小。首先刚来的会进入高优先级，如果没执行完进入下一级的优先级。只有上一个队列执行完后，才可以开始下一个队列。缺点还是长作业的问题，加入上一级队列一直有作业，那下一级别的队列的进程就会饥饿
  ```

  多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wtpuf9qaj315w0u040o.jpg" alt="截屏2022-11-07 20.13.11" style="zoom:33%;" />

  - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
  - 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
  - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；










### 线程

线程的优点：

- 一个进程中可以同时存在多个线程；
- 各个线程之间可以并发执行；
- 各个线程之间可以共享地址空间和文件等资源；

线程的缺点：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（C、C++里会，Java不会 。JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这两者不让它们崩溃。）



主要有三种线程的实现方式：

- **用户线程（\*User Thread\*）**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
- **内核线程（\*Kernel Thread\*）**：在内核中实现的线程，是由内核管理的线程；
- **轻量级进程（\*LightWeight Process\*）**：在内核中来支持用户线程；





#### ⚠️为什么要有多线程？【1】





## 调度

### ⚠️操作系统的调度算法【3】

- **进程调度**（详见上文进程调度算法）

  - 先来先服务调度算法
  - 最短作业优先调度算法
  - 高响应比优先调度算法
  - 时间片轮转调度算法
  - 最高优先级调度算法
  - 多级反馈队列调度算法

- **内存页面置换算法**

  - 最佳页面置换算法（OPT）

    置换在「未来」最长时间不访问的页面。（很理想，但是实际系统中无法实现，因为程序访问页面时是动态的。最佳页面置换算法作用是为了衡量你的算法的效率）

  - 先进先出置换算法（FIFO）

    选择在内存驻留时间很长的页面进行中置换。

  - 最近最久未使用（LRU）的置换算法

    选择最长时间没有被访问的页面进行置换。

    虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

  - 时钟页面置换算法（Lock）

    把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

    当发生缺页中断时，算法首先检查表针指向的页面：

    - 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
    - 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

  - 最不常用（LFU）算法

    当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。

- **磁盘调度算法**

  - 先来先服务

  - 最短寻道时间优先（SSF）

    优先选择从当前磁头位置所需寻道时间最短的请求。

    但这个算法可能存在某些请求的饥饿，产生饥饿的原因是磁头在一小块区域来回移动。

  - 扫描算法（电梯算法）

    磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。

    中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。

  - 循环扫描算法

    只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。

  - LOOK 与 C-LOOK 算法

    磁头在移动到「最远的请求」位置，然后立即反向移动。





### ⚠️LRU？如何实现LRU【2】

最近最久未使用（LRU）的置换算法的基本思路是，**发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。**

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最近最久未使用的置换算法" style="zoom: 33%;" />

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。











### 操作系统的中断【1】

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。

为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。

- **上半部用来快速处理中断**，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- **下半部用来延迟处理上半部未完成的工作**，一般以「内核线程」的方式运行。



### 操作系统的并发了解吗【1】





## 锁

https://www.xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html#%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81

### 死锁怎么产生的？怎么避免？【1】

死锁：两个或两个以上线程都在等待对方执行完毕**释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

四个必要条件：

1. 互斥条件：一个资源只能被一个进程所使用
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可抢占条件：进程已获得的资源，在未使用完之前，不能强行剥夺
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系





**如何解决？**

最常见：**使用资源有序分配法，来破循环与等待条件**。

（互斥不可破坏）

（不可抢占条件破坏代价大，实现复杂）

- 破坏请求与保持条件：

  允许进程获取初期所有资源后，便开始运行，运行过程中再逐步释放自己占有的资源

- 破坏循环与等待条件：

  对各进程请求资源的顺序做一个规定，避免相互等待。线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。





### 操作系统层面上，锁是如何实现的？【1】











## I/O

**零拷贝和异步I/O**

在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。

传输文件的时候，我们要根据文件的大小来使用不同的方式：

- 传输大文件的时候，使用「异步 I/O + 直接 I/O」；
- 传输小文件的时候，则使用「零拷贝技术」；



传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。

为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（`sendfile` 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84yusi6hdj31720pq76q.jpg" alt="截屏2022-11-14 21.15.24" style="zoom:33%;" />

<center>零拷贝</center>

当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84yv1xx6bj31bg0q40ut.jpg" alt="截屏2022-11-14 21.15.44" style="zoom:33%;" />

<center>异步IO</center>



### I/O 多路复用

一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，**多个请求复用了一个进程，这就是多路复用**，这种思想很类似一个 CPU 并发多个进程，所以也叫做**时分多路复用**。

我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84zbmjog2j31460nymxz.jpg" alt="截屏2022-11-14 21.31.36" style="zoom:33%;" />



https://zhuanlan.zhihu.com/p/126278747

select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。

(fd：文件描述符)



**select**

1. 在调用select之前告诉select 应用进程需要监控哪些fd可读、可写、异常事件，这些分别都存在一个fd_set数组中。
2. 应用进程调用select的时候把3个fd_set传给内核（产生了一次fd_set在用户空间到内核空间的复制），内核收到fd_set后对fd_set进行遍历，然后一个个去扫描对应fd是否满足可读写事件。
3. 如果发现了有对应的fd有读写事件后，内核会把fd_set里没有事件状态的fd句柄清除，然后把有事件的fd返回给应用进程（这里又会把fd_set从内核空间复制用户空间）。
4. 最后应用进程收到了select返回的活跃事件类型的fd句柄后，再向对应的fd发起数据读取或者写入数据操作。



缺陷：

1. 每次调用select，都需要把被监控的fds集合从用户态空间拷贝到内核态空间，高并发场景下这样的拷贝会使得消耗的资源是很大的。
2. 能监听端口的数量有限，单个进程所能打开的最大连接数有FD_SETSIZE宏定义
3. 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次收集可读事件：仅仅关心是否有数据可读这样一个事件



**poll**

poll模型里面通过使用链表的形式来保存自己监控的fd信息，正是这样poll模型里面是没有了连接限制，可以支持高并发的请求。

和select还有一点不同的是保存在链表里的需要监控的fd信息采用的是pollfd的文件格式，select 调用返回的fd_set是只包含了上次返回的活跃事件的fd_set集合，下一次调用select又需要把这几个fd_set清空，重新添加上自己感兴趣的fd和事件类型，而poll采用的pollfd 保存着对应fd需要监控的事件集合，也保存了一个当返回于激活事件的fd集合。 所以重新发请求时不需要重置感兴趣的事件类型参数。

```
struct pollfd{
	int fd;  // 文件描述符
	short events; // 注册的事件
	short revents;  // 实际发生的事件，由内核填充
}
```



select 和 poll 简述：

```
首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。
```



**epoll**

1. 创建内核事件表（epoll_create）。

   向内核申请创建一个fd的文件描述符作为内核事件表（B+树结构的文件，没有数量限制），这个描述符用来保存应用进程需要监控哪些fd和对应类型的事件。

2. 添加或移出监控的fd和事件类型（epoll_ctl）

   调用此方法可以是向内核的内核事件表 动态的添加和移出fd 和对应事件类型

3. epoll_wait 绑定回调事件

   内核向事件表的fd绑定一个回调函数。

   当监控的fd活跃时，会调用callback函数把事件加到一个**活跃事件队列**里;

4. 最后在epoll_wait 返回的时候内核会把活跃事件队列里的fd和事件类型返回给应用进程。

特点：

从epoll整体思路上来看，采用**事先就在内核创建一个事件监听表，后面只需要往里面添加移出对应事件**，因为本身事件表就在内核空间，所以就避免了向select、poll一样每次都要把自己需要监听的事件列表传输过去，然后又传回来，这也就避免了事件信息需要在用户空间和内核空间相互拷贝的问题。

epoll并不是像select一样去遍历事件列表，然后逐个轮询的监控fd的事件状态，而是**事先就建立了fd与之对应的回调函数，当事件激活后主动回调callback函数**，这也就避免了遍历事件列表的这个操作，所以epoll并不会像select和poll一样随着监控的fd变多而效率降低。



**比较表格**

|              | select                                                       | poll                                                         | epoll                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |
| 性能         | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能基本没有变化                |
| 连接数       | 一般1024                                                     | 无限制                                                       | 无限制                                            |
| 内存拷贝     | 每次调用select拷贝                                           | 每次调用poll拷贝                                             | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 数据结构     |                                                              |                                                              | 红黑树                                            |
| 内在处理机制 | 线性轮询                                                     | 线性轮询                                                     | FD挂在红黑树，通过事件回调callback                |
| 时间复杂度   | O(n)                                                         | O(n)                                                         | O(1)                                              |



#### 有了解epoll吗？可以说说吗？【1】

<font color=grey>epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</font>

（流程详见上面的4点。）

优势：

1. epoll 在内核里使用红黑树来跟踪进程所有待检测的fd，把需要监控的 socket 通过 `epoll_ctl()` 函数加入内核中的红黑树里，增删改一般时间复杂度是 `O(logn)`。select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
2. epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h851wwaetlj30xb0fdwfr.jpg" alt="截屏2022-11-14 23.01.15" style="zoom: 50%;" />

epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。

- 边缘触发模式，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次
- 水平触发模式，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；



#### ⚠️select poll 和 epoll 最大的差别是什么【1】

select 和 poll 每次都需要两次复制、两次遍历。

epoll 仅在第一次创建红黑树，后续都是对红黑树进行管理，增删改时间复杂度 O(logn)，减少了拷贝和内存分配；事件驱动，维护活跃事件队列，只将有事件发生的 Socket 集合传递给应用程序。



#### ⚠️操作系统的 IO 模型(阻塞，非阻塞，IO多路复用，信号驱动IO，异步IO)【1】



#### ⚠️一次普通 IO 的过程，什么时候用到了系统调用【1】



#### 介绍下 IO 多路复用【1】

最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。

传统的方式是使用多进程/线程模型，每来一个客户端连接，就分配一个进程/线程，后续的读写都在对应的进程/线程。但是当随着客户端数量的增长，大量的进程/线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。

为了解决上面这个问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下有三种提供 I/O 多路复用的 API，分别是：select、poll、epoll。

再继续介绍 select、poll、epoll ...







## Linux

**查看socket**

可以使用 `netstat` 或者 `ss`，这两个命令查看 socket、网络协议栈、网口以及路由表的信息。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h852p02lgej30k907rq3q.jpg" alt="截屏2022-11-14 23.28.18" style="zoom: 67%;" />

socket 的状态（*State*）、接收队列（*Recv-Q*）、发送队列（*Send-Q*）、本地地址（*Local Address*）、远端地址（*Foreign Address*）、进程 PID 和进程名称（*PID/Program name*）等。

当 socket 状态处于 `Established`时：

- *Recv-Q* 表示 socket 缓冲区中还没有被应用程序读取的字节数；
- *Send-Q* 表示 socket 缓冲区中还没有被远端主机确认的字节数；

而当 socket 状态处于 `Listen` 时：

- *Recv-Q* 表示全连接队列的长度；
- *Send-Q* 表示全连接队列的最大长度

在 TCP 三次握手过程中，当服务器收到客户端的 SYN 包后，内核会把该连接存储到半连接队列，然后再向客户端发送 SYN+ACK 包，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后<font color=red>创建新的完全的连接，并将其增加到全连接队列</font> ，等待进程调用 `accept()` 函数时把连接取出来。



**查看协议栈**

TCP显示了主动连接（*active connections openings*）、被动连接（*passive connection openings*）、失败重试（*failed connection attempts*）、发送（*segments send out*）和接收（*segments received*）的分段数量等各种信息

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h852tzj6cpj30ih0nygol.jpg" alt="截屏2022-11-14 23.33.05" style="zoom:33%;" />





#### ⚠️Linux如何查看哪些端口建立tcp连接？这些端口都有哪些状态？为什么要有time-wait？【1】

`netstat` 或者 `ss`

(listien,established,time-wait等等)。

状态：ESTABLISHED, CLOSE_WAIT, SYN_SENT, FIN_WAIT, TIME_WAIT 等等



为什么要有time-wait 见 `TCP/四次挥手`



#### 敲kill -9命令发生了什么。-9是什么意思【1】

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程；



## 待分类

#### ⚠️操作系统的临界区了解吗



#### ⚠️大端和小端有什么区别？



#### ⚠️用户态和内核态



#### ⚠️read 在三者中是用户发起还是内核发起？(用户发起)







# 计算机网络

## 通用

### ⚠️OSI七层模型【3】和五层模型？

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxkih9fn8pj313q0ja0wd.jpg" alt="截屏2021-12-20 19.14.11" style="zoom:33%;" />





**五层模型**

- 应用层：应用层是网络协议的最高层，主要任务**通过进程间的交互完成特定网络应用**。应用层协议定义的是 **应用程序（进程）间通信和交互的规则**。

  应用层协议有 HTTP、FTP、Telnet、DNS、SMTP等。应用层交互的数据单元称为 **报文**。

- 传输层：它负责**为两台主机中的进程提供通信服务**。该层主要有以下两种协议：

- - 传输控制协议 (Transmission Control Protocol，TCP)：提供**面向连接的、可靠的**数据传输服务，数据传输的基本单位是报文段（segment）；拥有流量控制、超时重传、拥塞控制等特性。
  - 用户数据报协议 (User Datagram Protocol，UDP)：提供**无连接的、尽最大努力的**数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。

- 网络层：网络层负责**为分组网络中的不同主机提供通信服务**，**并通过选择合适的路由将数据传递到目标主机**。在发送数据时，网络层把运输层产生的报文段或用户数据封装成 **分组** 或 包 进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫 **IP数据报**。

  IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。

- 数据链路层：数据链路层通常简称为 链路层。数据链路层在两个相邻节点传输数据时，**将网络层交下来的IP数据报组装成帧，在两个相邻节点之间的链路上传送 帧。**

- 物理层：保证数据可以在各种物理媒介上进行传输，**为数据的传输提供可靠的环境**。



**TCP/IP的体系结构**

应用层、传输层、网络层..

网络接口层：在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。

网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。





#### ⚠️802.3x 工作在几层，为什么【1】





## http

### http

#### ⚠️浏览器输入url到页面显示的过程【4】

1. 输入url

2. DNS解析（解析过程见下一节）

   查询的两种方式：递归和迭代

3. 建立TCP连接

4. 客户端发送HTTP报文

5. 服务器处理请求

6. 服务器响应请求，返回HTTP报文

7. 浏览器展示HTML

8. 浏览器发送请求获取其他在HTML中的资源





#### 分别介绍 http 1.1 2.0 3.0【1】

**http 1.1**

HTTP/1.1 相比 HTTP/1.0 性能上的改进：

- 使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。（解决了请求的队头阻塞）

但 HTTP/1.1 还是有性能瓶颈：

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是<font color=blue>队头阻塞</font>；
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。



**http 2.0**

HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。

那 HTTP/2 相比 HTTP/1.1 性能上的改进：

- 头部压缩

  如果同时发出多个请求，他们的头是一样的或是相似的，那么，协议会消除重复的部分。

  这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。

- 二进制格式

  全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。

- 并发传输

  引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并行交错地发送请求和响应。

- 服务器主动推送资源

  改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应。

  客户端和服务器双方都可以建立 Stream， Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号



缺陷：

TCP层的队头阻塞问题

HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85yg0xs0xj30ls07wgm7.jpg" alt="截屏2022-11-15 17.46.51" style="zoom:33%;" /> <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85ygmbsr8j30g40d7mxw.jpg" alt="截屏2022-11-15 17.47.25" style="zoom:33%;" />

一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。



**http 3.0**

HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP，基于 UDP 的 `QUIC` 协议 可以实现类似 TCP 的可靠性传输

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85ymj2fz7j30lg0a9gmo.jpg" alt="截屏2022-11-15 17.53.05" style="zoom: 50%;" />

QUIC 有以下 3 个特点。

- 无队头阻塞

  QUIC 连接上的多个 Stream 之间并没有依赖。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题

- 更快的连接建立

  对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，需要分批次来握手，先 TCP 握手，再 TLS 握手。

  QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8617ke356j30m80csq42.jpg" alt="截屏2022-11-15 19.22.30" style="zoom:50%;" />

  （甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。）

- 连接迁移

  基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

  QUIC通过**连接 ID**来标记通信的两个端点，只要保有上下文信息（比如连接 ID、TLS 密钥等），就可以复用原连接，消除重连的成本。







#### http 状态码【1】

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" />

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思





#### ⚠️get和post请求的区别【2】





#### ⚠️http 报文介绍【1】



#### ⚠️http 报文头和报文体分隔符是什么？\r\n 是什么意思(回车+换行)【1】







### https

#### https的过程【2】（如何建立，交互了什么）

TCP三次握手、TLS四次通信（TLS 1.3 改进成三次）

 ```
  SSL/TLS 协议基本流程：
  
  - 客户端向服务器索要并验证服务器的公钥。
  - 双方协商生产「会话秘钥」。
  - 双方采用「会话秘钥」进行加密通信。
 ```

TLS 协议建立的详细流程：

1. ClientHello

   客户端向服务器发起加密通信请求。发送以下信息：

   - 客户端支持的 TLS 协议版本，如 TLS 1.2 版本
   - 客户端生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。
   - 客户端支持的密码套件列表，如 RSA 加密算法

2. SeverHello

   服务器收到客户端请求后，向客户端发出响应，回应的内容如下：

   - 确认 TLS 协议版本
   - 服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。
   - 确认的密码套件列表，如 RSA 加密算法。
   - 服务器的数字证书。

3. 客户端回应

   确认服务器的数字证书的真实性，**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

   - 一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。
   - 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
   - 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

4. 服务器的最后回应

   收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。向客户端发送最后的信息：

   - 加密通信算法改变通知
   - 服务器握手结束通知

至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。





  



#### https一定安全吗？

HTTPS 协议本身到目前为止还是没有任何漏洞的，即使成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85xzbsy0rj30lt0jddi1.jpg" alt="截屏2022-11-15 17.30.46" style="zoom: 50%;" />

中间人攻击发生场景是有前提的，前提是<u>用户点击接受了中间人服务器的证书</u>。

中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。



#### 每次请求，https 的公私钥固定不变吗？【1】

(第一次会协商和加密，之后同一个浏览器的话会用 session id 做 session key 的提取，可以看做固定不变)







#### https 在传输消息前多出了几次 RTT(2-7次)【1】







#### http和https的区别【3】

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



**HTTPS 解决了 HTTP 的哪些问题？**

HTTP 由于是明文传输，所以安全上存在以下三个风险：

- **窃听风险**，比如通信链路上可以获取通信内容
- **篡改风险**，比如强制植入垃圾广告，视觉污染
- **冒充风险**，比如冒充淘宝网站

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了上述的风险：

- **信息加密**：交互信息无法被窃取
- **校验机制**：无法篡改通信内容，篡改了就不能正常显示
- **身份证书**



**HTTPS 是如何解决上面的三个风险的？**

- **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。

  对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

  用摘要算法（哈希函数）来计算出内容的哈希值。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85wr6n56mj30mp0ar74w.jpg" alt="截屏2022-11-15 16.48.20" style="zoom: 50%;" />

- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

  权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85wu9kcczj30mw0g8tao.jpg" alt="截屏2022-11-15 16.51.19" style="zoom:50%;" />





### 加密

#### ⚠️为什么需要 非对称加密 和 对称加密？





## DNS

#### DNS解析过程

1. 解析域名，浏览器查看（浏览器）缓存，再**查看 hosts 文件**，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。

2. 如果在本地的 hosts 文件没有对应的 ip 地址，浏览器会**发出一个 DNS请求到本地DNS服务器** 。

3. 查询的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先**查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归**的方式进行查询。如果没有，本地DNS服务器还要**向DNS根服务器进行查询**。

4. 根DNS服务器没有记录具体的域名和IP地址的对应关系，而是**告诉本地DNS服务器，你可以到顶级域名服务器上去继续查询**，并给出顶级域名服务器的地址。这种过程是迭代的过程。

5. 本地DNS服务器继续向顶级域名服务器发出请求，在这个例子中，请求的对象是.com顶级域名服务器。.com顶级域名服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是**告诉本地DNS服务器，你的域名的权威域名服务器的地址**。

6. 最后，本地DNS服务器向对应的权威域名服务器发出请求，这时就能收到一个域名和IP地址对应关系，**本地DNS服务器不仅要把IP地址返回给用户电脑**，还要把这个**对应关系保存在缓存中**，以备下次别的用户查询时，可以直接返回结果，加快网络访问。





## TCP/UDP

### TCP

TCP 是**面向连接的、可靠的、基于字节流的**传输层通信协议。



#### tcp与udp的区别【2】

1. 连接
   - TCP 是面向连接的传输层协议，传输数据前先要建立连接。
   - UDP 是不需要连接，即刻传输数据。
2. 服务对象
   - TCP 是一对一的两点服务，即一条连接只有两个端点。
   - UDP 支持一对一、一对多、多对多的交互通信
3. 可靠性
   - TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按序到达
   - UDP 是尽最大努力交付，不保证可靠交付数据。但是我们可以基于 UDP 传输协议实现一个可靠的传输协议，比如 QUIC 协议
4. 拥塞控制、流量控制
   - TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
   - UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率
5. 首部开销
   - TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。
   - UDP 首部只有 8 个字节，并且是固定不变的，开销较小。
6. 传输方式
   - TCP 是流式传输，没有边界，但保证顺序和可靠
   - UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。
7. 分片不同
   - TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片
   - UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。

TCP 和 UDP 应用场景：

 TCP 经常用于：`FTP` 文件传输；HTTP / HTTPS；

UDP 经常用于：包总量较少的通信，如 `DNS` 、`SNMP` 等；视频、音频等多媒体通信；广播通信；



#### ⚠️tcp为什么安全【1】







#### tcp的超时重传机制【1】

发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据。

TCP 会在以下两种情况发生超时重传：

- 数据包丢失
- 确认应答丢失

`RTT` 指的是**数据发送时刻到接收到确认的时刻的差值**，也就是包的往返时间。

**超时重传时间 RTO 的值应该略大于报文往返 RTT 的值**。

RFC6289 建议使用以下的公式计算 RTO：

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h87crkd972j30lv0g70u7.jpg" alt="截屏2022-11-16 22.47.51" style="zoom:50%;" />

其中 `SRTT` 是计算平滑的RTT ，`DevRTR` 是计算平滑的RTT 与 最新 RTT 的差距。

如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**

也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**



#### tcp快速重传

当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。





#### ⚠️tcp 和 udp 报文的区别(序号，确认号，数据偏移，标识符，窗口大小等)【1】







#### ⚠️tcp 可靠性，然后问十六位校验和怎么实现的【1】







#### ⚠️tcp 粘包【2】







#### 不同协议能否监听同一个端口

可以。

传输层的「端口号」的作用，是为了区分同一个主机上不同应用程序的数据包。

传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块。当主机收到数据包后，可以在 IP 包头的「协议号」字段知道该数据包是 TCP/UDP，所以可以根据这个信息确定送给哪个模块（TCP/UDP）处理，送给 TCP/UDP 模块的报文根据「端口号」确定送给哪个应用程序处理。





### ⭐️三次握手



<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h862fzwzmbj30ll0huwfu.jpg" alt="截屏2022-11-15 20.05.12" style="zoom:50%;" />

#### 三次握手过程

客户端和服务端都处于 `CLOSE` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态。

1. 客户端随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接。客户端处于 `SYN-SENT` 状态。
2. 服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`，接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端。之后服务端处于 `SYN-RCVD` 状态。
3. 客户端收到服务端报文后，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文可以携带客户到服务端的数据，之后客户端处于 `ESTABLISHED` 状态。

服务端收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。







#### 为什么需要三次握手

1. 防止旧的重复连接初始化造成混乱【主要原因】

   > *The principle reason for the three-way handshake is to prevent old duplicate connection initiations from causing confusion.*
   >
   > -- RFC 793

   - 客户端连续发送多次 SYN 建立连接的报文，在网络拥堵情况下，「旧 SYN 报文」比「最新的 SYN 」早到达了服务端，服务端返回 SYN + ACK，ACK是旧的客户端序号+1
   - 客户端收到后 ACK 与期望不符，回复 RST 报文请求终止旧的连接
   - 服务端收到 RST 报文后，就会释放连接
   - 后续最新的 SYN 抵达了服务端后，客户端与服务端就可以正常的完成三次握手了。

   **在两次握手的情况下，服务端没有中间状态给客户端来阻止历史连接，导致服务端可能建立一个历史连接，造成资源浪费**。

2. 同步双方初始序列号

   当客户端发送携带「初始序列号」的 `SYN` 报文的时候，需要服务端回一个 `ACK` 应答报文，表示客户端的 SYN 报文已被服务端成功接收

   那当服务端发送「初始序列号」给客户端的时候，依然也要得到客户端的应答回应，**这样一来一回，才能确保双方的初始序列号能被可靠的同步。**

   **两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。**

3. 避免资源浪费

   没有第三次握手，服务端不清楚客户端是否收到了自己回复的 ACK 报文，所以服务端每收到一个 SYN 就只能先主动建立一个连接。

   如果客户端发送的 SYN 报文在网络中阻塞了，重复发送多次 SYN 报文，那么服务端在收到请求后就会建立多个冗余的无效链接，造成不必要的资源浪费。



**为什么不是四次握手？**

服务端回复 ACK 和 发送 SYN 的过程可以合并。

三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。



⚠️**第1/2/3次握手丢失了，会发生什么？**



#### TCP SYN 攻击【1】

攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务端不能为正常用户服务。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzI1LmpwZw?x-oss-process=image/format,png" alt="SYN 攻击" style="zoom:50%;" />



**TCP 半连接和全连接队列**

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h87ayqiddyj30mq0f13zl.jpg" alt="截屏2022-11-16 21.45.31" style="zoom:50%;" />

正常流程：

- 当服务端接收到客户端的 SYN 报文时，会创建一个半连接的对象，然后将其加入到内核的「 SYN 队列」；
- 接着发送 SYN + ACK 给客户端，等待客户端回应 ACK 报文；
- 服务端接收到 ACK 报文后，从「 SYN 队列」取出一个半连接对象，然后创建一个新的连接对象放入到「 Accept 队列」；
- 应用通过调用 `accpet()` socket 接口，从「 Accept 队列」取出连接对象。

SYN 攻击方式最直接的表现就会把 TCP 半连接队列打满，这样**当 TCP 半连接队列满了，后续再在收到 SYN 报文就会丢弃**，导致客户端无法和服务端建立连接。



**避免 SYN 攻击方式**

- 调大 netdev_max_backlog；

  当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包，调大队列的最大值。

- 增大 TCP 半连接队列；

- 开启 tcp_syncookies；

  开启 syncookies 功能就可以在不使用 SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h87b1xx218j30m30g6jsg.jpg" alt="截屏2022-11-16 21.48.38" style="zoom: 50%;" />

  - 当 「 SYN 队列」满之后，后续服务端收到 SYN 包，不会丢弃，而是根据算法，计算出一个 `cookie` 值；
  - 将 cookie 值放到第二次握手报文的「序列号」里，然后服务端回第二次握手给客户端；
  - 服务端接收到客户端的应答报文时，服务端会检查这个 ACK 包的合法性。如果合法，将该连接对象放入到「 Accept 队列」。
  - 最后应用程序通过调用 `accpet()` 接口，从「 Accept 队列」取出的连接。

- 减少 SYN-ACK 重传次数

  减少 SYN-ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。







### 四次挥手

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h87b4gqrlkj30lq0m5wfy.jpg" alt="截屏2022-11-16 21.51.05" style="zoom:50%;" />

1. 客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。
2. 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSE_WAIT` 状态
3. 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态
4. 等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。
5. 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态
6. 服务端收到了 `ACK` 应答报文后，就进入了 `CLOSE` 状态，至此服务端已经完成连接的关闭。
7. 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSE` 状态，至此客户端也完成连接的关闭。

每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

<font color=red>**主动关闭连接的，才有 TIME_WAIT 状态**</font>



#### 为什么需要第四次挥手【3】

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

从上面过程可知，服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，因此是需要四次挥手。

（但是在特定情况下，四次挥手是可以变成三次挥手的）



**⚠️第1/2/3/4次挥手丢失了，会发生什么？**





#### timewait状态【4】

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

需要 TIME-WAIT 状态，主要是两个原因

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；

  **足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。**

- 保证「被动关闭连接」的一方，能被正确的关闭；

  > *TIME-WAIT - represents waiting for enough time to pass to be sure the remote TCP received the acknowledgment of its connection termination request.*
  >
  > --RFC 793

  **等待足够的时间以确保最后的 ACK 能让被动关闭方接收，从而帮助其正常关闭。**

  



#### ⚠️closewait状态【4】





#### 为什么time wait 等待时间是 2MSL

https://blog.csdn.net/Whatssssup/article/details/115029996

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间。超过这个时间报文将被丢弃。

TIME_WAIT 等待 2 倍的 MSL。

1. 为了保证主动关闭方的最后一个ACK报文段能够到达被动关闭方

   如果被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。

   （**2MSL时长** 这其实是相当于**至少允许报文丢失一次**。比如，若 ACK 在一个 MSL 内丢失，这样被动方重发的 FIN 会在第 2 个 MSL 内到达，TIME_WAIT 状态的连接可以应对。）

2. 防止“已失效的连接请求报文段”出现在本连接中。使本连接持续的时间内所产生的所有报文段都从网络中消失，这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。









### UDP

#### ⚠️如何设计一种机制在UDP上实现可靠传输？【1】

（确认和重传机制）补充？





### Socket编程

#### 了解socket编程吗，【2】其中accept方法是什么

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将 socket 绑定在指定的 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务端端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符（新的）；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h87cuzjoutj30mm0i1t9p.jpg" alt="截屏2022-11-16 22.51.08" style="zoom:50%;" />

监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。



**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**







#### ⚠️生成 tcp 和 udp socket有什么区别【1】

(在创建声明和 api 使用上均有区别)



#### socket 如何标识一个协议(sock_type)【1】

socket 的系统调用

```
int socket(int domain, int type, int protocal)
```

三个参数分别代表：

- domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL/AF_UNIX 用于本机；
- type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP；SOCK_DGRAM 表示的是数据报，对应 UDP；SOCK_RAW 表示的是原始套接字；
- protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；

根据创建 socket 类型的不同，通信的方式也就不同：

- 实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；
- 实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；
- 实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；









# 数据库

## Mysql

**执行一条 SQL 查询语句，期间发生了什么？**

- 连接器：建立连接，管理连接、校验用户身份；
- 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。**MySQL 8.0 已删除该模块**；
- 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
- 执行 SQL：执行 SQL 共有三个阶段：
  - 预处理阶段：检查表或字段是否存在；将 `select *` 中的 `*` 符号扩展为表上的所有列。
  - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
  - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h88btkpdw3j30uc0heac5.jpg" alt="截屏2022-11-17 19.00.45" style="zoom:50%;" />

### B+树

#### b + 树说一下？索引结构？【1】Mysql的底层实现【2】

https://mp.weixin.qq.com/s/w1ZFOug8-Sa7ThtMnlaUtQ

B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是**按主键顺序存放**的。

每一层父节点的索引值都会出现在下层子节点的索引值中，并且每一个叶子节点都有两个指针，分别指向下一个叶子节点和上一个叶子节点，形成一个双向链表。



B+ 树与 B 树差异的点，主要是以下这几点：

- 叶子节点（最底部的节点）才会存放实际数据（索引+记录），非叶子节点只会存放索引；
- 所有索引都会在叶子节点出现，叶子节点之间构成一个有序链表；
- 非叶子节点的索引也会同时存在在子节点中，并且是在子节点中所有索引的最大（或最小）。
- 非叶子节点中有多少个子节点，就有多少个索引





#### mysql的索引用的什么数据结构？为什么？原理是什么？【4】

MySQL 默认的存储引擎 InnoDB 采用的是 B+ 作为索引的数据结构，原因有：

- B+ 树的非叶子节点不存放实际的记录数据，仅存放索引，因此**数据量相同的情况下**，相比存储即存索引又存记录的 B 树，B+树的非叶子节点可以存放更多的索引，因此 B+ 树可以比 B 树更「矮胖」，**查询底层节点的磁盘 I/O次数会更少**。
- B+ 树有大量的冗余节点（所有非叶子节点都是冗余索引），这些冗余索引让 B+ 树在**插入、删除的效率都更高**，比如删除根节点的时候，不会像 B 树那样会发生复杂的树的变化；
- B+ 树叶子节点之间用链表连接了起来，**有利于范围查询**，而 B 树要实现范围查询，因此只能通过树的遍历来完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。





#### 从数据页的角度看 B+ 树

采用页的方式存储数据记录，索引和数据分开存储。

InnoDB 里的 B+ 树中的**每个节点都是一个数据页**。

数据页中的记录按照「主键」顺序组成单向链表。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h89jwa5e6sj30qo0cfgn0.jpg" alt="截屏2022-11-18 20.25.42" style="zoom: 50%;" />

**页目录就是由多个槽组成的，槽相当于分组记录的索引**。然后，因为记录是按照「主键值」从小到大排序的，所以**我们通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录**，无需从最小记录开始遍历整个页中的记录链表。





### 索引

索引的定义：帮助存储引擎快速获取数据的一种数据结构。



**索引的分类**

- 按「数据结构」分类：**B+tree索引、Hash索引、Full-text索引**。
- 按「物理存储」分类：**聚簇索引（主键索引）、二级索引（辅助索引）**。
- 按「字段特性」分类：**主键索引、唯一索引、普通索引、前缀索引**。
- 按「字段个数」分类：**单列索引、联合索引**。





#### 聚集索引和非聚集索引？【1】

主键索引的 B+Tree 和二级索引的 B+Tree 区别如下：

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。

在查询时使用了二级索引，如果查询的数据能在二级索引里查询的到，那么就不需要回表，这个过程就是覆盖索引。如果查询的数据不在二级索引里，就会先检索二级索引，找到对应的叶子节点，获取到主键值后，然后再检索主键索引，就能查询到数据了，这个过程就是回表。



InnoDB 在创建聚簇索引时，会根据不同的场景选择不同的列作为索引：

- 如果有主键，默认会使用主键作为聚簇索引的索引键；
- 如果没有主键，就选择第一个不包含 NULL 值的唯一列作为聚簇索引的索引键；
- 在上面两个都没有的情况下，InnoDB 将自动生成一个隐式自增 id 列作为聚簇索引的索引键；





#### 什么是回表？⚠️怎么减少回表？回表出现错误怎么办【1】

先检查二级索引中的 B+Tree 的索引值，找到对应的叶子节点，然后获取主键值，然后再通过主键索引中的 B+Tree 树查询到对应的叶子节点，然后获取整行数据。**这个过程叫「回表」，也就是说要查两个 B+Tree 才能查到数据**。





**索引下推**

在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

索引下推的大概原理是：截断的字段不会在 Server 层进行条件判断，而是会被下推到「存储引擎层」进行条件判断，然后过滤出符合条件的数据后再返回给 Server 层。由于在引擎层就过滤掉大量的数据，无需再回表读取数据来进行判断，减少回表次数，从而提升了性能。







#### 覆盖索引和聚簇索引【2】

这种在二级索引的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」，也就是只需要查一个 B+Tree 就能找到数据。不需要回表。





#### 范围查找可以用索引吗？【1】

（可以，但具体执行要看优化器如何优化）

可以。

多个普通字段组合在一起创建的索引就叫做联合索引。

联合索引的最左匹配原则，在遇到范围查询（如 >、<）的时候，就会停止匹配，也就是范围查询的字段可以用到联合索引，但是在范围查询字段的后面的字段无法用到联合索引。

注意，对于 >=、<=、BETWEEN、like 前缀匹配的范围查询，并不会停止匹配。（部分匹配）







#### ⚠️最左匹配原则。 怎么建立索引（我回答了最左匹配原则）【2】

使用联合索引时，存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。

在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性。

**利用索引的前提是索引里的 key 是有序的**。





#### 选择哪个字段作为索引？【1】

（面试官给了一个例子：查询一个student表，如果where条件中有性别和姓氏，应该选择哪个字段作为索引）

**建立联合索引时，要把区分度大的字段排在前面，这样区分度大的字段越有可能被更多的 SQL 使用到**。

区分度就是某个字段 column 不同值的个数「除以」表的总行数：

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h88edr57suj30ik05iwem.jpg" alt="截屏2022-11-17 20.29.22" style="zoom:50%;" />

比如，性别的区分度就很小，不适合建立索引或不适合排在联合索引列的靠前的位置，而 UUID 这类字段就比较适合做索引或排在联合索引列的靠前的位置。

因为如果索引的区分度很小，假设字段的值分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比（惯用的百分比界线是"30%"）很高的时候，它一般会忽略索引，进行全表扫描



#### 什么时候需要 / 不需要创建索引？

**什么时候适用索引？**

- 字段有唯一性限制的，比如商品编码；
- 经常用于 `WHERE` 查询条件的字段，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- 经常用于 `GROUP BY` 和 `ORDER BY` 的字段，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。



**什么时候不需要创建索引？**

- `WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段
- 字段中存在大量重复数据。比如性别字段，只有男女。MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- 表数据太少
- 经常更新的字段不用创建索引。因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，影响数据库性能





#### ⚠️除了B+树以外还有什么数据结构可以作为索引【3】

（hash、跳表）

MySQL 的 MyISAM 存储引擎支持多种索引数据结构，比如 B+ 树索引、R 树索引、Full-Text 索引。MyISAM 存储引擎在创建表时，创建的主键索引默认使用的是 B+ 树索引。

InnoDB 和 MyISAM 都支持 B+ 树索引，但是它们数据的存储结构实现方式不同。不同之处在于：

- InnoDB 存储引擎：B+ 树索引的叶子节点保存数据本身；
- MyISAM 存储引擎：B+ 树索引的叶子节点保存数据的物理地址；





#### 什么情况下会索引失效？

- like 关键字左或者左右模糊匹配

  索引 B+ 树是按照「索引值」有序排列存储的，只能根据前缀进行比较。

- 对索引使用函数

  因为索引保存的是索引字段的原始值，而不是经过函数计算后的值

- 对索引进行表达式计算

- 对索引隐式类型转换

  例如：如果索引字段是字符串类型，但是在条件查询中，输入的参数是整型，会进行全表查询。

  MySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。

  （所以如果查询的是 where phone = 1111111111，MySQL 会把等号左边的 phone 索引转换成 int，即进行了表达式计算；

  如果查询的是 where id = "1"，MySQL 会把等号右边的 "1" 转换成 int，而左边的索引并没有受影响，所以此时索引没失效。）

- 联合索引非最左匹配

  在联合索引的情况下，数据是按照索引第一列排序，第一列数据相同时才会按照第二列排序。

- WHERE 子句中的 OR

  如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。



### 事务

**事务的四个特性（ACID）**

- **原子性（Atomicity）**：一个事务中的所有操作，要么全部完成，要么全部不完成。事务在执行过程中发生错误，会被回滚到事务开始前的状态。
- **一致性（Consistency）**：是指事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。
- **隔离性（Isolation）**：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致，因为多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。
- **持久性（Durability）**：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。



**InnoDB 引擎通过什么技术来保证事务的这四个特性的呢？**

- 持久性是通过 redo log （重做日志）来保证的；
- 原子性是通过 undo log（回滚日志） 来保证的；
- 隔离性是通过 MVCC（多版本并发控制） 或锁机制来保证的；
- 一致性则是通过持久性+原子性+隔离性来保证；





**事务并发问题**

- 脏读：读到其他事务未提交的数据；
- 不可重复读：前后读取的数据不一致；
- 幻读：前后读取的记录数量不一致。





**事务的隔离级别**

- 读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；
- 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；
- 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；
- 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h89lo61ycmj30m809gaab.jpg" alt="截屏2022-11-18 21.27.08" style="zoom:50%;" />

**MySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很大程度上避免幻读现象（并不是完全解决了**）

解决的方案有两种：

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。



⚠️**四个隔离级别如何实现？**

| 隔离级别 | 脏读   | 不可重复读 | 幻读   | 实现原理                                                     |
| -------- | ------ | ---------- | ------ | ------------------------------------------------------------ |
| 未提交读 | 可能   | 可能       | 可能   | 直接读取最新的数据                                           |
| 已提交读 | 不可能 | 可能       | 可能   | 在「每个语句执行前」都会重新生成一个 Read View               |
| 可重复读 | 不可能 | 不可能     | 可能   | 「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。 |
| 可串行化 | 不可能 | 不可能     | 不可能 | 读写锁                                                       |







#### 说一下MVCC【1】

Read View 有四个重要的字段：

- m_ids ：指的是在创建 Read View 时，当前数据库中「活跃事务」的**事务 id 列表**，注意是一个列表，**“活跃事务”指的就是，启动了但还没提交的事务**。
- min_trx_id ：指的是在创建 Read View 时，当前数据库中「活跃事务」中事务 **id 最小的事务**，也就是 m_ids 的最小值。
- max_trx_id ：这个并不是 m_ids 的最大值，而是**创建 Read View 时当前数据库中应该给下一个事务的 id 值**，也就是全局事务中最大的事务 id 值 + 1；
- creator_trx_id ：指的是**创建该 Read View 的事务的事务 id**。



聚簇索引记录中都包含下面两个隐藏列（在**undo log** 里）：

- trx_id，当一个事务对某条聚簇索引记录进行改动时，就会**把该事务的事务 id 记录在 trx_id 隐藏列里**；
- roll_pointer，每次对某条聚簇索引记录进行改动时，都会把旧版本的记录写入到 undo 日志中，然后**这个隐藏列是个指针，指向每一个旧版本记录**，于是就可以通过它找到修改前的记录。



在创建 Read View 后，我们可以将记录中的 trx_id 划分这三种情况：

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h89m6bom1fj30ly09ymy2.jpg" alt="截屏2022-11-18 21.44.33" style="zoom:50%;" />

- 如果记录的 trx_id 值小于 Read View 中的 `min_trx_id` 值，表示这个版本的记录是在创建 Read View **前**已经提交的事务生成的，所以该版本的记录对当前事务**可见**。
- 如果记录的 trx_id 值大于等于 Read View 中的 `max_trx_id` 值，表示这个版本的记录是在创建 Read View **后**才启动的事务生成的，所以该版本的记录对当前事务**不可见**。
- 如果记录的 trx_id 值在 Read View 的 `min_trx_id` 和 `max_trx_id` 之间，需要判断 trx_id 是否在 m_ids 列表中：
  - 如果记录的 trx_id **在** `m_ids` 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务**不可见**。
  - 如果记录的 trx_id **不在** `m_ids`列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务**可见**。

**这种通过「版本链」来控制并发事务访问同一个记录时的行为就叫 MVCC（多版本并发控制）。**





#### ⚠️幻读是什么，解决方案





### 锁

**锁的分类**

- 粒度：
  - 全局锁
  - 表级锁
    - 表锁
    - 元数据锁
    - 意向锁
    - AUTO-INC 锁
  - 行级锁
    - Record Lock 记录锁
    - Gap Lock 间隙锁
    - Next-Key Lock 临键锁
    - 意向锁
- 方式：读锁（共享锁） / 写锁（排他锁、独占锁）
- 态度：悲观锁 / 乐观锁
  - 悲观锁 （读锁、写锁都是悲观锁）
  - 乐观锁 （乐观锁，需要外部程序实现）

（详细的介绍在 https://www.xiaolincoding.com/mysql/lock/mysql_lock.html#%E5%85%A8%E5%B1%80%E9%94%81）



#### 了解Mysql的悲观锁和乐观锁吗？简单介绍一下【2】

https://blog.csdn.net/weixin_45433031/article/details/120838045

**悲观锁（Pessimistic Concurrency Control）**

在修改数据之前先锁定，再修改的方式。

悲观锁，具有强烈的独占和排他特性。它指的是对数据被外界（包括本系统当前的其他事务，以及来自外部系统的事务处理）修改持保守态度。因此，在整个数据处理过程中，将数据处于锁定状态。

总是假设最坏的情况，每次读取数据的时候都默认其他线程会更改数据，因此需要进行加锁操作，当其他线程想要访问数据时，都需要阻塞挂起。

悲观锁的实现：传统的关系型数据库使用这种锁机制，比如行锁、表锁、读锁、写锁等，都是在操作之前先上锁；Java 里面的同步 synchronized 关键字的实现

悲观锁主要分为共享锁和排他锁：

- 共享锁（shared locks）又称为读锁，简称 S 锁。共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。
- 排他锁（exclusive locks）又称为写锁，简称 X 锁。排他锁就是不能与其他锁并存，如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁。获取排他锁的事务可以对数据行读取和修改。



**乐观锁（Optimistic Locking）**

乐观锁假设数据一般情况不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。乐观锁适用于读多写少的场景，这样可以提高程序的吞吐量。

乐观锁的实现：CAS （Compare And Set）：Java 中并发库原子变量使用了乐观锁的一种 CAS 实现方式；版本号控制：一般是在数据表中加上一个数据版本号 version 字段，表示数据被修改的次数。当数据被修改时，version 值会 +1。当线程 A 要更新数据时，在读取数据的同时也会读取 version 值，在提交更新时，若刚才读取到的 version 值与当前数据库中的 version 值相等时才更新，否则重试更新操作，直到更新成功。

乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。



#### ⚠️如果删除索引出现问题了导致锁表怎么办？【1】





### 日志

**undo log（回滚日志）**

是 Innodb 存储引擎层生成的日志，实现了事务中的原子性，主要用于事务回滚和 MVCC。

undo log 是一种用于撤销回退的日志。在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。

每当 InnoDB 引擎对一条记录进行操作（修改、删除、新增）时，要把回滚时需要的信息都记录到 undo log 里

一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id



undo log 两大作用：

- **实现事务回滚，保障事务的原子性**。事务处理过程中，如果出现了错误或者用户执 行了 ROLLBACK 语句，MySQL 可以利用 undo log 中的历史数据将数据恢复到事务开始之前的状态。
- **实现 MVCC（多版本并发控制）关键因素之一**。MVCC 是通过 ReadView + undo log 实现的。undo log 为每条记录保存多份历史数据，MySQL 在执行快照读（普通 select 语句）的时候，会根据事务的 Read View 里的信息，顺着 undo log 的版本链找到满足其可见性的记录。







**redo log（重做日志）**

是 Innodb 存储引擎层生成的日志，实现了事务中的持久性，主要用于掉电等故障恢复；

当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，**这个时候更新就算完成了**。InnoDB 引擎会在适当的时候，由后台线程将缓存在 Buffer Pool 的脏页刷新到磁盘里，这就是 **WAL （Write-Ahead Logging）技术**。

redo log 是物理日志，记录了某个数据页做了什么修改，每当执行一个事务就会产生这样的一条或者多条物理日志。在事务提交时，只要先将 redo log 持久化到磁盘即可，可以不需要等到将缓存在 Buffer Pool 里的脏页数据持久化到磁盘。

系统崩溃重启后，可以根据 redo log 的内容，将所有数据恢复到最新的状态。



redo log 的作用：

- **实现事务的持久性，让 MySQL 有 crash-safe 的能力**，能够保证 MySQL 在任何时间段突然崩溃，重启后之前已提交的记录都不会丢失；
- **将写操作从「随机写」变成了「顺序写」**， MySQL 的写操作并不是立刻更新到磁盘上（随即写），而是先记录在日志上（顺序写），然后在合适的时间再更新到磁盘上 。提升 MySQL 写入磁盘的性能。



**redo log 和 undo log 区别？**

- undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；
- redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；

事务提交之前发生了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发生了崩溃，重启后会通过 redo log 恢复事务。







**binlog （归档日志）**

是 Server 层生成的日志，主要用于数据备份和主从复制；

MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写入 binlog 文件。

binlog 文件是记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作



**redo log 和 binlog 有什么区别？**

1. 适用对象不同

   binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；redo log 是 Innodb 存储引擎实现的日志

2. 文件格式不同

   binlog 有 3 种格式类型，分别是 STATEMENT（默认格式）、ROW、 MIXED；redo log 是物理日志

3. 写入方式不同

   binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志；

   redo log 是循环写，日志空间大小是固定，保存未被刷入磁盘的脏页日志

4. 用途不同

   binlog 用于备份恢复、主从复制

   redo log 用于掉电等故障恢复



#### 数据库binlog,redolog,undolog的区别【1】











### ⚠️其他

连接操作join了解嘛？（左连接，右连接，内连接）



inner join连接操作怎么实现的？（大概讲了下流程，应该是问底层）



join的时间复杂度？（加索引和不加索引）



不加索引怎么优化连接操作？（大表在前，小表在后）还有嘛？（加缓存？不太确定）



底层硬盘宕掉怎么办



内部节点 和 叶子节点 满足一页数据页吗



主从同步（异步，半同步）







## Redis（跳过）

redis有哪些数据类型【2】



为什么要用redis？有考虑过redis失效，也就是服务宕机的情况吗？



redis缓存击穿，缓存穿透，缓存雪崩



redis 持久化的方式(RDB, AOF)【2】









# ⚠️数据结构

### 哈希

hashmap原理



哈希索引【2】hash说一下？hash为什么不能范围查找？减少Hash冲突的办法？



哈希和B+树查询数据的时间复杂度（答了哈希O(1)，B+树$O(log_{m}n)$其实就是树高



跳表怎么实现



哈希表怎么实现，讲哈希冲突的时候讲了开放寻址法、拉链法，然后问除了这两个还有其他方法吗（不知道



红黑树，立刻说我红黑树不熟悉，然后就问了一个：红黑树是不是二叉平衡树，回答是特殊的平衡树，然后讲红黑树性质就没了





### 红黑树



红黑树和B+树的区别



B+树属于二叉树么



### 排序

说一下拓扑排序



堆排序过程。时间复杂度。维护堆过程。堆中插入一个节点和删除一个节点的流程，时间空间复杂度。



你熟悉什么排序，各种排序的时间复杂度



堆排序建堆过程，建堆时间复杂度





# Golang

## 基础

#### ⚠️go 与其他语言的不同【1】





#### 函数传指针和传值有什么区别？【1】

值传递只会把参数的值复制⼀份放进临时生成的内存空间，两个变量的地址不同，不可相互修改

引⽤传递会将变量的内存地址寻找方式传入，在函数中可以对该变量值的内容进行修改

golang默认都是采用值传递（array也是值传递），即拷贝传递，有些值默认就是指针（slice、map、channel） 



#### new和make有什么区别？【1】

（指针、slice 切片、管道 channel、接口 interface、map、函数等都是引用类型）

new()对类型进行内存分配,入参为类型,返回为**类型的指针**，指向分配类型的内存地址

make()也是用于内存分配的，但是和new不同，它**只**用于channel、map以及slice的内存创建和初始化，而且它返回的类型就是这三个**类型本身**。

```
func new(Type) *Type
func make(t Type, size ...IntegerType) Type
```



#### make一个slice后返回的是指针吗？map呢？【1】

不是，返回的是slice类型本身



#### 为什么Golang可以很容易实现高并发【1】

https://blog.csdn.net/big_white_py/article/details/111465167

1. Golang实现了 CSP 并发模型做为并发基础。Goroutine 是go实际并发执行的实体。底层使用协程（coroutine）实现并发，coroutine是一种运行在用户态的用户线程，避免了内核态和用户态的切换；可以由语言和框架层进行调度；具有更小的栈空间，允许创建大量的实例
2. 实体间通过 channel 进行匿名消息传递，实现实体中间的解耦。
3. 在语言层面实现了自动调度，goroutine是可以被异步抢占。并且go对网络IO库进行了封装，屏蔽了很多内部细节，对外提供统一的语法关键字支持，简化了并发程序编写的成本。



#### go的slice内部有什么？【1】

slice底层是一个struct。包含指向数组的指针、切片长度、切片当前容量。

```
// runtime/slice.go
type slice struct {
    array unsafe.Pointer// 指向数组的指针
    len   int
    cap   int
}
```



#### go slice 和 array 区别【1】

**Array**

数组（Array）是一个由固定长度的特定类型元素组成的序列，一个数组可以由零个或多个元素组成。因其**长度的不可变动**，数组在Go中很少直接使用。把一个大数组传递给函数会消耗很多内存。一般采用数组的切片。

**Slice**

Slice是一种数据结构，描述与Slice变量本身分开存储的Array的连续部分。 Slice不是Array。Slice描述了Array的一部分。

slice底层是一个struct。包含指向数组的指针、切片长度、切片当前容量。可以通过append追加元素。

```
// runtime/slice.go
type slice struct {
    array unsafe.Pointer// 指向数组的指针
    len   int
    cap   int
}
```



#### slice的扩容【1】

**扩容的整体逻辑**

1. 根据**growslice**计算扩容后的cap
2. 根据计算出cap申请内存（创建新的数组）
3. 将原slice的数据拷贝到新内存中（新数组）
4. 返回新slice，新slilce指向新数组





#### 一个函数传参一个slice，先append再赋值和另一个函数先赋值再append，哪个会发生变化？【1】

https://www.golangroadmap.com/interview/books/go/gobase/311.html#%E7%AD%94%E6%A1%88-%E5%A4%A7%E5%B8%83%E4%B8%81

没啥意义这题。

先append再赋值：最后是赋值的结果

先赋值再append：赋值+append



#### go的map是线程安全的吗？【1】

https://www.cnblogs.com/peteremperor/p/14469710.html

不是线程安全的。

安全地使用map的方式：

- 增加同步机制，加锁。sync.RWMutex。
- sync.Map。并发安全的字典类型sync.Map，可以显著地减少锁的争用



#### 对象是什么。面向对象有什么好处？go 中如何实现多态

对象是类的实例，是面向对象编程中基本的运行实体。

面向对象的好处：

- 封装可以提高类的易用行、减少编程过程中代码出错的风险
- 继承可以实现代码的复用
- 抽象可以让程序的设计和实现分离
- 多态提高了程序的可拓展性

Go 中一个类型如果定义了接口的所有方法，那它就隐式地实现了该接口。

所有实现了接口的类型，都可以把它的值保存在一个接口类型的变量中。在 Go 中，我们使用接口的这种特性来实现多态。



#### go怎么实现封装、继承、多态【1】

**封装**





**继承**

如果一个struct嵌套了另一个匿名结构体，那么这个结构体可以直接访问匿名结构体的字段和方法，从而实现继承特性。 同时，一个struct还可以嵌套多个匿名结构体，那么该struct可以直接访问嵌套的匿名结构体的字段和方法，从而实现多重继承。



**多态**

（基类指针可以指向任何派生类的对象，并在运行时绑定最终调用的方法的过程被称为多态。）

golang中采用接口实现多态。golang里面有一个接口类型interface，任何类型只要实现了接口的方法，都可以赋值给该接口类型。





## 协程

#### ⚠️golang中协程的概念【1】



#### 了解GMP模型吗，介绍一下？【2】

https://blog.csdn.net/qq_39679639/article/details/124372554

CPU线程切换的开销是影响性能的一个因素，Go提供了一种机制，可以在用户空间实现任务的切换，上下文切换成本更小，可以达到使用较少的线程数量实现较大并发的能力，即**GMP模型**

- `G(Goroutine)`: 即Golang协程，协程是一种用户态线程，比内核态线程更加轻量。使用go关键字可以创建一个Golang协程
- `M(Machine)`: 即工作线程。实质上实现业务逻辑的载体
- `P(Processor)`: 处理器。是Golang内部的定义，非CPU。包含运行Go代码的必要资源，也有调度Goroutine的能力

**`M`必须拥有`P`，才能执行`G`中的代码，`P`负责`G`的调度**，

同时运行的 M个数，也即线程数一般等同于CPU的个数，以达到尽可能的使用CPU而又不至于产生过多的线程切换开销

模型结构如下

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8c6pebzo9j30y40u0ta0.jpg" alt="截屏2022-11-21 03.06.01" style="zoom: 33%;" />



**Processor常规调度**

每个`P`维护一个`G`队列，`P`周期性的将`G`调度到`M`上执行一小段时间，然后保存上下文，并将次`G`放到队列末尾，继续执行下一个`G`

除了每个Processor拥有的G队列以外，Go还维护一个全局G队列（**主要是一些从系统调用I/O中恢复的G**） ，Processor还会周期的查看全局G队列中时候有就绪的G，有的话就拿到自己的队列中，防止全局队列中的G被“饿死”



**Processor系统调用**

当Processor中的G产生系统调用/IO时，处理流程如下，假设此时运行线程为M0：

1. Processor感知M0正在处理的协程G0处于系统调用的阻塞状态
2. Processor将G0从自己的G队列中移除
3. Processor重新申请新的M1，来继续执行G队列
   - 如果有空闲的M，则直接复用空闲M
   - 如果无空间的M，则新建一个线程M
4. M0执行完G0的系统调用后，G0将存放在全局G队列中，等待某个Processor唤起
5. 同时M0也进入空闲状态，等待其他P复用，或者被销毁

所以，**系统中M的个数通常会略多于P的个数，但同时执行的M个数和P数量一样**





### channel

#### 缓冲channel 和 无缓冲 channel

1. 无缓冲channel，创建方式为 make(chan TYPE) 。每一个发送者与接收者都会阻塞当前线程，只有当接受者与发送者都准备就绪了，channel才能正常使用。
2. 缓冲channel 即 buffer channel 创建方式为 make(chan TYPE, SIZE) c2<-1 则不会阻塞，因为缓冲大小是3，只有前三个值都还没被人拿走，这时候才会阻塞。



#### 协程之间怎么通信/一组协程完成后需要通知其他协程，可以怎么办？【2】

新建一个channel，元素为bool，容量为总协程个数。

每个写成退出的时候想这个channel 写入一个 true。

被通知的协程从channel 中取数据，当取出了全部结果后，就表示该组协程都已经完成。





#### ⚠️channel了解吗，channel的工作原理是什么？【1】

https://blog.csdn.net/qq_43510019/article/details/116853985

**数据结构**

- 环形队列

  chan内部实现了一个环形队列作为其缓冲区

- 等待队列

  从channel读数据，如果channel缓冲区为空或者没有缓冲区，当前goroutine会被阻塞。
  向channel写数据，如果channel缓冲区已满或者没有缓冲区，当前goroutine会被阻塞。

  被阻塞的goroutine将会挂在channel的等待队列

- 类型

  一个channel只能传递一种类型的值，类型信息存储在hchan数据结构中

- 锁

  一个channel同时仅允许被一个goroutine读写



**channel读写（操作）**

- 创建channel
- 写数据
- 读数据
- 关闭channel





#### 向一个已经关闭的channel发送数据，会发生什么；从一个已经关闭的channel中接收数据，会发生什么【1】

对一个已经关闭的channel取数据，如果里面有值会先取值，当值完后会取到该channel类型的零值。

向一个已近关闭的channel发送数据，会panic: send on closed channel

关闭一个已经关闭的channel，会panic: close of closed channel

（遍历一个没有关闭的channel 会报dead lock）



## GC

https://blog.csdn.net/qq_45738177/article/details/125359749

https://zhuanlan.zhihu.com/p/518984548

https://www.bilibili.com/video/BV1wz4y1y7Kd?p=6&vd_source=f86a3c07e572293f592691638d279e85

### 标记清除（Go V1.3）

- 暂停程序（Stop The World, STW），将程序中的对象分为可达和不可达
- 对可达对象进行标记，然后清除不可达对象
- 停止暂停，程序继续执行，直到程序结束



### 三色标记法（Go V1.5）

三色可达性分析标记算法按“是否被访问过”将程序中的对象分成白色、黑色和灰色：

- 白色对象 — 对象尚未被垃圾收集器访问过，在可达性分析刚开始的阶段，所有的对象都是白色的，若在分析结束阶段，仍然是白色的对象，即代表不可达。
- 黑色对象 — **表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经被扫描过**，黑色的对象代表已经被扫描过而且是安全存活的，如果有其他对象指向黑色对象无需再扫描一遍，黑色对象不可能直接（不经过灰色对象）指向某个白色对象。
- 灰色对象 — **表示对象已经被垃圾收集器访问过，但是这个对象上至少存在一个引用还没有被扫描过**，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象。



1. 存在STW的三色标记法

   - 程序起初创建的对象都设为白色
   - GC开始时从根结点开始遍历所有对象，把遍历（非递归遍历）到的对象从白色标记为灰色
   - 遍历灰色对象，将灰色对象引用的对象标记为灰色，同时将该灰色对象标记为黑色
   - 重复上一步骤，直到没有灰色标记的对象
   - 将剩余所有白色结点进行删除回收

2. 没有STW的三色标记法

   如果并发执行（不使用STW），用户程序可能在标记执行的过程中修改对象的指针。

   可能导致：

   - 把原本应该垃圾回收的死亡对象错误的标记为存活，不过会在下次垃圾收集中清理。
   - 把原本存活的对象错误的标记为已死亡，导致“对象消失”，这在内存管理中是非常严重的错误。

   <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8c05gll8lj30s00q8dgk.jpg" alt="截屏2022-11-20 23.19.14" style="zoom:33%;" />



### 屏障技术

“对象消失”的问题的两个条件：

- 赋值器插入了一条或多条从黑色对象到白色对象的新引用；
- 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。

保证垃圾收集算法的正确性，只需破坏这两个条件的任意一个即可，屏障技术就是在并发或者增量标记过程中保证三色不变性的重要技术。



**强三色不变式**

强制不允许黑色对象引用白色对象

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8c0cou4ouj30ly0bymxh.jpg" alt="截屏2022-11-20 23.26.13" style="zoom:50%;" />

**弱三色不变式**

黑色对象可以引用白色对象，白色对象存在其他灰色对象对它的引用，或者可达它的链路上游存在灰色对象。（即所有被黑色对象引用的白色对象都被灰色对象保护着）

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8c0f2j2z1j317m0igjsu.jpg" alt="截屏2022-11-20 23.28.30" style="zoom: 40%;" />



#### 插入屏障

`具体操作`：在A对象引用B对象的时候，B对象被标记为灰色。(将B挂在A下游，B必须被标记为灰色)

`满足`：**强三色不变式**. (不存在黑色对象引用白色对象的情况了， 因为白色会强制变成灰色)

注：**插入屏障只在堆区对象中使用**，在栈中执行三色标记过程会启动STW。在准备回收白色前，重新遍历扫描一次栈空间，加STW暂停保护栈，将栈的对象进行一次三色标记，直到没有灰色节点，再进行垃圾回收。

不足：结束后需要STW重新扫描栈。

```
func DijkstraWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) 
     shade(ptr)  //先将新下游对象 ptr 标记为灰色
     *slot = ptr
}

//说明：
添加下游对象(当前下游对象slot, 新下游对象ptr) { 
 //step 1
 标记灰色(新下游对象ptr) 
 
 //step 2
 当前下游对象slot = 新下游对象ptr 
}

//场景：
A.添加下游对象(nil, B) //A 之前没有下游， 新添加一个下游对象B， B被标记为灰色
A.添加下游对象(C, B) //A 将下游对象C 更换为B， B被标记为灰色
```





#### 删除屏障

`具体操作`: 被删除的对象，如果自身为灰色或者白色，那么被标记为灰色。

`满足`: **弱三色不变式**. (保护灰色对象到白色对象的路径不会断)

不足：一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉。回收精度较低。

```
func YuasaWritePointer(slot *unsafe.Pointer, ptr unsafe.Pointer) {
    shade(*slot) 先将*slot标记为灰色
    *slot = ptr
}
//说明：
添加下游对象(当前下游对象slot， 新下游对象ptr) {
  //step 1
  if (当前下游对象slot是灰色 || 当前下游对象slot是白色) {
          标记灰色(当前下游对象slot)     //slot为被删除对象， 标记为灰色
  }  
  //step 2
  当前下游对象slot = 新下游对象ptr
}

//场景
A.添加下游对象(B, nil)   //A对象，删除B对象的引用。B被A删除，被标记为灰(如果B之前为白)
A.添加下游对象(B, C)     //A对象，更换下游B变成C。B被A删除，被标记为灰(如果B之前为白)
```



### 三色标记法+混合写屏障（Go V1.8）

（建议看完下面这个视频的后几集）

https://www.bilibili.com/video/BV1wz4y1y7Kd?p=9&vd_source=f86a3c07e572293f592691638d279e85

https://blog.csdn.net/weixin_43566459/article/details/123907548

`具体操作`：

- GC开始时将栈上的对象全部扫描并标记为黑色(之后不再进行第二次重复扫描，无需STW)，
- GC期间，任何在栈上<font color=blue>创建</font>的新对象，均为黑色。
- 堆中被删除的对象标记为灰色。
- 堆中被添加的对象标记为灰色。

注：栈不触发屏障机制！即栈中被删除/添加的对象不会标记为灰色。（第二行“任何在栈上<font color=blue>创建</font>的新对象，均为黑色”是有效的，因为这不是屏障机制）



应用场景：

1. 对象被一个堆对象删除引用，成为栈对象的下游
2. 对象被一个栈对象删除引用，成为另一个栈对象的下游
3. 对象被一个堆对象删除引用，成为另一个堆对象的下游
4. 对象从一个栈对象删除引用，成为另一个堆对象的下游





#### ⚠️golang的GC【2】

发展：标记清理 -> 三色标记法 -> 混合写屏障





#### ⚠️三色标记法的灰色、黑色有什么区别？为什么区分灰色和黑色，灰色存在的意义？【1】

- 黑色对象 — **表示对象已经被垃圾收集器访问过，且这个对象的所有引用都已经被扫描过**，黑色的对象代表已经被扫描过而且是安全存活的，如果有其他对象指向黑色对象无需再扫描一遍
- 灰色对象 — **表示对象已经被垃圾收集器访问过，但是这个对象上至少存在一个引用还没有被扫描过**，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象。





⚠️灰色的意义：



#### 写屏障是什么？【1】

内存屏障技术是一种屏障指令，它可以让CPU或者编译器在执行内存相关操作时遵循特定的约束，像是一个钩子函数。

【插入屏障和删除屏障的相关说明】



#### 什么是内存逃逸，在什么情况下发生，原理是什么?【1】

https://www.11meigui.com/2022/golang-memory-escape.html

栈是线程级别的，大小在创建的时候已经确定，当变量太大的时候，会"逃逸"到堆上，这种现象称为**内存逃逸**。



内存逃逸的场景：

- 指针逃逸：

  Go可以返回局部变量指针，这种情况下，函数虽然退出了，但是因为指针的存在，对象的内存不能随着函数结束而回收，因此只能分配在堆上。

- 栈空间不足逃逸：

  当栈空间不足以存放当前对象时或无法判断当前切片长度时会将对象分配到堆中

- interface{} 动态类型逃逸

  在 Go 中，空接口 interface{} 可以表示任意的类型，如果函数参数为 interface{}，编译期间很难确定其参数的具体类型，也会发生逃逸。

- 闭包引用对象逃逸



**逃逸分析基本原则**

编译器会根据变量是否被外部引用来决定是否逃逸：

- 如果函数外部没有引用，则优先放到栈中；
- 如果函数外部存在引用，则必定放到堆中;
- 如果栈上放不开，则必定放到堆上;



**内存逃逸分析的好处**

- 栈上分配内存比在堆中分配内存效率更高
- 栈上分配的内存不需要 GC 处理，而堆需要
- 逃逸分析目的是决定内分配地址是栈还是堆
- 逃逸分析在编译阶段完成





## 框架

#### 介绍Gin框架



**Gin 框架的优点**

- 快速：基于Radix树的路由
- 支持中间件：内置许多中间件，如Logger,Gzip,Authorization, Recover等。
- 崩溃恢复：可以捕捉panic引发的程序崩溃，使Web服务可以一直运行。
- JSON验证：可以验证请求中JSON数据格式。
- 路由分组：支持路由分组(RouteGroup)，可以更方便组织路由
- 多种数据渲染方式：支持HTML、JSON、YAML、XML等数据格式的响应。
- 扩展性：非常简单扩展中间件。



#### ⚠️Gin框架吧，为什么使用Gin框架？可以大概说一下Gin框架的具体实现吗？【1】

https://blog.csdn.net/qq_40369829/article/details/121645618



- 初始化

  - 创建Engine

    r := gin.New()生成了一个Engine对象，Engine对象是整个框架的核心，也包含了对路由的操作和许多成员变量，其中包括路由要执行的任务链HandlersChain，方法树methodTrees等。

  - 注册路由和中间件

    1. 计算绝对路径
    2. 添加handlers
    3. 关联绝对路径和handlers

  - 开启服务

    底层原生net/http

- 处理请求

  - 匹配路由
    1. 匹配HTTP method对应的基数树
    2. 基数树中寻找handlers
  - 执行
    1. 执行中间件+业务逻辑的职责链
    2. 如果自定义中间件，可以使用next()实现切面





### 中间件

Gin框架允许开发者在处理请求的过程中，加入用户自己的钩子（Hook）函数。这个钩子函数就叫中间件，中间件适合处理一些公共的业务逻辑，比如登录认证、权限校验、数据分页、记录日志、耗时统计等。



Gin中的中间件实际上还是一个Gin中的 gin.HandlerFunc。中间都是需要注册后才能启用的。

中间件分类：

- 全局中间件：全局中间件设置之后对全局的路由都起作用。
- 路由组中间件：路由组中间件仅对该路由组下面的路由起作用。
- 单个路由中间件：单个路由中间件仅对一个路由起作用。



#### Gin框架的中间件是怎么实现的？有了解吗？【1】

https://blog.csdn.net/weixin_38753143/article/details/125916902

https://zhuanlan.zhihu.com/p/507085115

1. 注册过程：Gin把中间件和处理函数统一定义为一个handleFunc，将这些 handleFunc 结合到一起组成一条处理函数链条`HandlersChain`，本质上就是一个由`HandlerFunc`组成的切片
2. 执行过程：通过索引遍历`HandlersChain`链条，中间使用c.next、c.Abort等函数来进行流程控制，c.Set() 和 c.Get() 这两个方法多用于在多个函数之间通过 c 传递数据的。





### 路由

路由的过程：

**注册路由**

r.GET("/user/:name", routeUser)定义一个GET请求，模糊匹配/user/:name。

1. 将相对路径 join为绝对路径
2. 【注册中间件在这一步？】判断handlersChain的长度，不能超过math.MaxInt8 / 2并且把路由方法装载到handlersChain里面去。
3. 关联绝对路径和handlers，存入engine.trees 路由树。
4. 返回当前对象，达到能使用链式操作的目的



**访问路由**

输入localhost:8080/user/abc，首先进入net的ServeHTTP()方法。然后被gin框架handleHTTPRequest()方法接受。遍历之前注册的路由树engine.tress。

使用算法匹配。





#### Gin框架的路由树的实现。【1】

https://zhuanlan.zhihu.com/p/491337692

https://blog.csdn.net/www_xuhss_com/article/details/123321209

https://www.cnblogs.com/yuanwebpage/p/16812610.html

使用 Radix Tree 基数树或压缩前缀树。是一种更节省空间的 Trie 树。

字典树是一棵多叉树。从根节点到某一节点，路径上经过的字符连接起来，为该节点对应的字符串。除根节点外，每一个节点只包含一个字符。每个节点的所有子节点包含的字符都不相同。

基数树是对字典树的压缩。父节点下第一级子节点数小于 2 的都可以进行压缩，把子节点合并到父节点上

压缩字典树每个节点上存储着一个或多个字符；**父节点上存储的字符为所有子节点的公共前缀。**

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h8c4axx9k5j30qy0fmt9z.jpg" alt="截屏2022-11-21 01.42.56" style="zoom:50%;" />

对于有大量公共前缀的多个字符串，采用radix tree可以显著减少节点数量，加快匹配速度。而URL路由就存在大量的公共前缀，因此很适合用radix tree来存储路由信息。



httprouter中的基数树

```
type node struct {
	path      string    // 节点对应的字符串路径
	wildChild bool      // 是否为参数节点，如果是参数节点，那么 wildChild=true
    nType     nodeType  // 节点类型，有几个枚举值可以看下面nodeType的定义
	maxParams uint8     // 节点路径最大参数个数
	priority  uint32    // 节点权重，子节点的handler总数
	indices   string    // 节点与子节点的分裂的第一个字符
	children  []*node   // 子节点
	handle    Handle    // http请求处理方法
}

```



**httprouter概述**

gin的路由注册采用的是httprouter。httprouter是基于radix tree实现的前缀匹配。httprouter在实现radix tree时增加了一些针对url的优化：

（1）**每一种http方法各一个 radix tree**，这样可以提高匹配效率；
（2）提供了通配符 ":" 和 "\*"，其中 ":"+参数名称 表示路径参数，比如 GET /template/:user_id，其中 ":user_id" 就是一个路径参数，访问时用户输入url： /template/12345，则user_id=12345。"\*"+参数名称 为匹配所有参数，结构只能为 .../.../.../\*param_name，"\*" 只能作为结尾参数。



# ⚠️通用

如果要设计一个秒杀系统，需要加锁？加到哪一层？代码？数据库？网关



有了解过微服务的基本原理吗？



微服务是怎么实现鉴别不同的服务的？



了解IO多路复用吗？可以说说大致的实现吗？



#### 介绍下 jwt

https://blog.csdn.net/abcnull/article/details/122871443

| 构成      | 名称          | 描述                                                  |
| --------- | ------------- | ----------------------------------------------------- |
| Header    | 头部          | Token类型和签名算法（HMAC SHA256、HS384）。           |
| Payload   | 载荷（Claim） | 承载的内容或携带的信息，如用户名、过期时间等。        |
| Signature | 签名          | 由Header、Payload、自己维护的一个Secret经过加密得来。 |

Signature会将Header和Payload进行Base64编码后，使用Header中声明的加密算法加盐（Serect）生成。由于是Base64编码相当于明文可见。



**过程简介**

- 登录的 HandlerFunc 中，需要生成 token，并设置响应头带上这个 token
- 中间件可以处理分组的请求，检测 Authorization 中数据做解析判定数据是否有效，如果无效直接返回无权限，不会进入到具体 HandlerFunc 中操作，如果有效则把 claims 中的用户信息保存到 gin.context 中，然后放行进入 HandlerFunc 中



**GenerateToken 生成 *jwt.Token**

一般在 login 后来生成 *jwt.Token 存放在响应头中给浏览器



**login 登录后响应头设置 cookie**

login 登录之后需要把 token string 带到响应头中返回给前端浏览器来保存信息



**middlerware 中写法**

中间件中做到解析 token，然后把 token 中的用户信息存放在 gin.Context 中，方便后面 HandlerFunc 中取用



**ParseToken 解析 token string => *jwt.Token**





# 算法题

最大岛屿数量



反转一个带符号的整数：-32变为-23.整数在[-2^31, 2^31-1]之间；需要注意输入数据的类型和是否结果会溢出



分苹果



求一个数组的所有可能的元素集合



二叉树中序遍历 



返回一个大数的阶乘结果，输入为字符串，输出也为字符串



二叉树转双向链表。



LC 394 字符串解码



最长连续序列



有n个"("和")"，输出所有的排列组合



根节点到叶子节点路径和为目标值的路径



口述链表是否存在环。数学证明。过渡到如果快指针一次走三步行不行。【2】



一个数组，元素从两边到中间单调递增，找出元素种类的个数。[4,5,6,9,7,6,5,1] 结果应该返回6。面试的话应该空间复杂度O(1)才能通过（双指针？）



接雨水



删除链表中的重复元素2



字典序的第K小数字



去除链表中重复元素



最长的格式正确的括号字符串



输入 n，给出 1~n 的所有排列，不要求输出有序

即 输入 3，输出 1，2，3，12，13，23，123



需要几个栈实现一个队列，两个，口述压队出队





# 智力题

烧绳子，接水。



32个球，重量都不一样，只有一个天平，需要多少次才能找到最终的？需要多少次才能找到第二重的？



# 场景题

设计一个邀请码，数字字母组成，固定长度，唯一，邀请码之间变化比较大。考虑了半天，说了个错误的。8会，想了解的同学可以参考base62编码规则。



两个大文件找重复行





# 其他

怎么确定走go语言技术栈的