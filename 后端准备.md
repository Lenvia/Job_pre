[TOC]

# 操作系统

## 进程、线程、协程

#### 进程、线程、协程的区别【4】

线程与进程的比较如下：

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；
- 线程能减少并发执行的时间和空间开销；
  - 线程的创建时间比进程快（不会涉及这些资源管理信息）
  - 线程的终止时间比进程快（释放的资源相比进程少）
  - 同一个进程内的线程切换比进程切换快（虚拟内存共享）
  - 线程之间数据传递的时候，就不需要经过内核



#### 什么时候用线程，什么时候用协程





#### 共享内存的实现方式





### 进程

####  进程状态【2】

在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。

- 运行状态（*Running*）：该时刻进程占用 CPU；
- 就绪状态（*Ready*）：可运行，由于其他进程处于运行状态而暂时停止运行；
- 阻塞状态（*Blocked*）：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；

进程还有另外两个基本状态：

- 创建状态（*new*）：进程正在被创建时的状态；
- 结束状态（*Exit*）：进程正在从系统中消失时的状态；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wsycw76wj31fe0hy402.jpg" alt="截屏2022-11-07 19.46.47" style="zoom:33%;" />

在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。就需要一个新的状态，来**描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态**。

挂起状态可以分为两种：

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；
- 就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wt4wmlp9j31bg0u0mzr.jpg" alt="截屏2022-11-07 19.53.04" style="zoom:33%;" />



#### 进程间通信【2】

每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

**管道、消息队列、共享内存、信号量、套接字**

- 管道

  管道传输数据是单向的。A进程将数据以字节流写入管道，B进程需要等待A进程将信息写完以后才能读出来。

  比如 ps -f | grep xxx

  缺点：效率低，不适合进程间频繁地交换数据

- 消息队列

  在发送数据时，按照一个个独立单元发送，发送方和接收方约定好消息的类型和格式

  缺点：不适合比较大数据的传输；存在用户态与内核态之间的数据拷贝开销

- 共享内存

  申请一块虚拟地址空间，不同进程通过这块虚拟地址空间映射到相同的物理地址空间。无需拷贝。

  缺点：会出现冲突

- 信号量

  防止多进程竞争共享资源，而造成的数据错乱的一个约束和保护机制。使得共享的资源，在任意时刻只能被一个进程访问。

  信号量表示资源的数量，控制信号量的方式有两种原子操作：P 操作和 V 操作。P 操作为申请资源，V 操作是归还资源。

  信号初始化为 1，就代表着是**互斥信号量**，它可以保证共享内存在任何时刻只有一个进程在访问；信号初始化为 0，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执行

- 信号

  信号是进程间通信机制中唯一的**异步通信机制**，因为可以在任何时候发送信号给某一进程，一旦有信号产生，就有下面这几种，用户进程对信号的处理方式：

  - 执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。
  - 捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。
  - 忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 `SIGKILL` 和 `SEGSTOP`，它们用于在任何时候中断或结束某一进程

- 套接字

  跨网络与不同主机上的进程之间通信

  domain 参数用来指定协议族、type 参数用来指定通信特性、protocal 参数原本是用来指定通信协议的（废弃）

  - TCP 协议通信的 socket 编程模型

    服务端和客户端初始化 socket -> 服务端 bind 绑定 IP 和端口 -> 服务端调用 listen 监听 -> 服务端调用 accept 等待客户端连接 -> 客户端调用 connect 发起连接请求 -> **服务端 accept 返回用于传输 socket 的文件描述符** -> 客户端 write 服务端read 

  - UDP 协议通信的 socket 编程模型

    只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind

  - 本地进程间通信的 socket 编程模型

    本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别



#### 进程调度算法

- 先来先服务调度算法

  每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。

- 最短作业优先调度算法

  ```
  优先把短作业执行完，再执行长作业。缺点是如果短作业很多，长作业会被搁置。
  ```

  优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。

- 高响应比优先调度算法

  ```
  是在短作业优先的基础上改进，加上一个随时间叠加的权重。等待时间越长，权重越高。
  这种算法既可以优先完成短作业，又能确保长作业不会长期饥饿。
  ```

  每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wtlcdnq5j314w0bqmy7.jpg" alt="截屏2022-11-07 20.08.52" style="zoom:25%;" />

  （高响应比优先调度算法是「理想型」的调度算法，现实中是实现不了的）

- 时间片轮转调度算法

  ```
  定义一个时间片长度，平均给每个进程分配时间片，一旦时间片用完，作业就会由进行转为就绪，等待重新被调度。缺点是如果作业比较多，那长作业可能需要好几轮才可以被执行完。
  ```

  每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。

  - 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；
  - 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

- 最高优先级调度算法

  从就绪队列中选择最高优先级的进程进行运行。

  进程的优先级可以分为，静态优先级和动态优先级：

  - 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
  - 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。

- 多级反馈队列调度算法

  ```
  设置了不同的队列，可以分类为高、中、低优先级。优先级越高，分配的时间片越小。首先刚来的会进入高优先级，如果没执行完进入下一级的优先级。只有上一个队列执行完后，才可以开始下一个队列。缺点还是长作业的问题，加入上一级队列一直有作业，那下一级别的队列的进程就会饥饿
  ```

  多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h7wtpuf9qaj315w0u040o.jpg" alt="截屏2022-11-07 20.13.11" style="zoom:33%;" />

  - 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
  - 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
  - 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；










### 线程

线程的优点：

- 一个进程中可以同时存在多个线程；
- 各个线程之间可以并发执行；
- 各个线程之间可以共享地址空间和文件等资源；

线程的缺点：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃（C、C++里会，Java不会 。JVM 自定义了自己的信号处理函数，拦截了 SIGSEGV 信号，针对这两者不让它们崩溃。）



主要有三种线程的实现方式：

- **用户线程（\*User Thread\*）**：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；
- **内核线程（\*Kernel Thread\*）**：在内核中实现的线程，是由内核管理的线程；
- **轻量级进程（\*LightWeight Process\*）**：在内核中来支持用户线程；





#### 为什么要有多线程？





## 调度

### ⚠️操作系统的调度算法【3】

- **进程调度**（详见上文进程调度算法）

  - 先来先服务调度算法
  - 最短作业优先调度算法
  - 高响应比优先调度算法
  - 时间片轮转调度算法
  - 最高优先级调度算法
  - 多级反馈队列调度算法

- **内存页面置换算法**

  - 最佳页面置换算法（OPT）

    置换在「未来」最长时间不访问的页面。（很理想，但是实际系统中无法实现，因为程序访问页面时是动态的。最佳页面置换算法作用是为了衡量你的算法的效率）

  - 先进先出置换算法（FIFO）

    选择在内存驻留时间很长的页面进行中置换。

  - 最近最久未使用（LRU）的置换算法

    选择最长时间没有被访问的页面进行置换。

    虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

  - 时钟页面置换算法（Lock）

    把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

    当发生缺页中断时，算法首先检查表针指向的页面：

    - 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
    - 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

  - 最不常用（LFU）算法

    当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰。

- **磁盘调度算法**

  - 先来先服务

  - 最短寻道时间优先（SSF）

    优先选择从当前磁头位置所需寻道时间最短的请求。

    但这个算法可能存在某些请求的饥饿，产生饥饿的原因是磁头在一小块区域来回移动。

  - 扫描算法（电梯算法）

    磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向。

    中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。

  - 循环扫描算法

    只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。

  - LOOK 与 C-LOOK 算法

    磁头在移动到「最远的请求」位置，然后立即反向移动。





### LRU？如何实现LRU

最近最久未使用（LRU）的置换算法的基本思路是，**发生缺页时，选择最长时间没有被访问的页面进行置换，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。**

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png" alt="最近最久未使用的置换算法" style="zoom: 33%;" />

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。









### 操作系统的中断

中断是系统用来响应硬件设备请求的一种机制，操作系统收到硬件的中断请求，会打断正在执行的进程，然后调用内核中的中断处理程序来响应请求。

中断处理程序在响应中断时，可能还会「临时关闭中断」，这意味着，如果当前中断处理程序没有执行完之前，系统中其他的中断请求都无法被响应，也就说中断有可能会丢失，所以中断处理程序要短且快。

为了解决中断处理程序执行过长和中断丢失的问题，将中断过程分成了两个阶段，分别是「上半部和下半部分」。

- **上半部用来快速处理中断**，一般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情。
- **下半部用来延迟处理上半部未完成的工作**，一般以「内核线程」的方式运行。



### 操作系统的并发了解吗





## 锁

https://www.xiaolincoding.com/os/4_process/pessim_and_optimi_lock.html#%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81

### 死锁怎么产生的？怎么避免？

死锁：两个或两个以上线程都在等待对方执行完毕**释放锁**，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了**死锁**。

四个必要条件：

1. 互斥条件：一个资源只能被一个进程所使用
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可抢占条件：进程已获得的资源，在未使用完之前，不能强行剥夺
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系





**如何解决？**

最常见：**使用资源有序分配法，来破循环与等待条件**。

（互斥不可破坏）

（不可抢占条件破坏代价大，实现复杂）

- 破坏请求与保持条件：

  允许进程获取初期所有资源后，便开始运行，运行过程中再逐步释放自己占有的资源

- 破坏循环与等待条件：

  对各进程请求资源的顺序做一个规定，避免相互等待。线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。





### 操作系统层面上，锁是如何实现的？











## I/O

**零拷贝和异步I/O**

在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。

传输文件的时候，我们要根据文件的大小来使用不同的方式：

- 传输大文件的时候，使用「异步 I/O + 直接 I/O」；
- 传输小文件的时候，则使用「零拷贝技术」；



传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。

为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（`sendfile` 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84yusi6hdj31720pq76q.jpg" alt="截屏2022-11-14 21.15.24" style="zoom:33%;" />

<center>零拷贝</center>

当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84yv1xx6bj31bg0q40ut.jpg" alt="截屏2022-11-14 21.15.44" style="zoom:33%;" />

<center>异步IO</center>



### I/O 多路复用

一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，**多个请求复用了一个进程，这就是多路复用**，这种思想很类似一个 CPU 并发多个进程，所以也叫做**时分多路复用**。

我们熟悉的 select/poll/epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h84zbmjog2j31460nymxz.jpg" alt="截屏2022-11-14 21.31.36" style="zoom:33%;" />



https://zhuanlan.zhihu.com/p/126278747

select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。

(fd：文件描述符)



**select**

1. 在调用select之前告诉select 应用进程需要监控哪些fd可读、可写、异常事件，这些分别都存在一个fd_set数组中。
2. 应用进程调用select的时候把3个fd_set传给内核（产生了一次fd_set在用户空间到内核空间的复制），内核收到fd_set后对fd_set进行遍历，然后一个个去扫描对应fd是否满足可读写事件。
3. 如果发现了有对应的fd有读写事件后，内核会把fd_set里没有事件状态的fd句柄清除，然后把有事件的fd返回给应用进程（这里又会把fd_set从内核空间复制用户空间）。
4. 最后应用进程收到了select返回的活跃事件类型的fd句柄后，再向对应的fd发起数据读取或者写入数据操作。



缺陷：

1. 每次调用select，都需要把被监控的fds集合从用户态空间拷贝到内核态空间，高并发场景下这样的拷贝会使得消耗的资源是很大的。
2. 能监听端口的数量有限，单个进程所能打开的最大连接数有FD_SETSIZE宏定义
3. 被监控的fds集合中，只要有一个有数据可读，整个socket集合就会被遍历一次收集可读事件：仅仅关心是否有数据可读这样一个事件



**poll**

poll模型里面通过使用链表的形式来保存自己监控的fd信息，正是这样poll模型里面是没有了连接限制，可以支持高并发的请求。

和select还有一点不同的是保存在链表里的需要监控的fd信息采用的是pollfd的文件格式，select 调用返回的fd_set是只包含了上次返回的活跃事件的fd_set集合，下一次调用select又需要把这几个fd_set清空，重新添加上自己感兴趣的fd和事件类型，而poll采用的pollfd 保存着对应fd需要监控的事件集合，也保存了一个当返回于激活事件的fd集合。 所以重新发请求时不需要重置感兴趣的事件类型参数。

```
struct pollfd{
	int fd;  // 文件描述符
	short events; // 注册的事件
	short revents;  // 实际发生的事件，由内核填充
}
```



select 和 poll 简述：

```
首先需要把关注的 Socket 集合通过 select/poll 系统调用从用户态拷贝到内核态，然后由内核检测事件，当有网络事件产生时，内核需要遍历进程关注 Socket 集合，找到对应的 Socket，并设置其状态为可读/可写，然后把整个 Socket 集合从内核态拷贝到用户态，用户态还要继续遍历整个 Socket 集合找到可读/可写的 Socket，然后对其处理。
```



**epoll**

1. 创建内核事件表（epoll_create）。

   向内核申请创建一个fd的文件描述符作为内核事件表（B+树结构的文件，没有数量限制），这个描述符用来保存应用进程需要监控哪些fd和对应类型的事件。

2. 添加或移出监控的fd和事件类型（epoll_ctl）

   调用此方法可以是向内核的内核事件表 动态的添加和移出fd 和对应事件类型

3. epoll_wait 绑定回调事件

   内核向事件表的fd绑定一个回调函数。

   当监控的fd活跃时，会调用callback函数把事件加到一个**活跃事件队列**里;

4. 最后在epoll_wait 返回的时候内核会把活跃事件队列里的fd和事件类型返回给应用进程。

特点：

从epoll整体思路上来看，采用**事先就在内核创建一个事件监听表，后面只需要往里面添加移出对应事件**，因为本身事件表就在内核空间，所以就避免了向select、poll一样每次都要把自己需要监听的事件列表传输过去，然后又传回来，这也就避免了事件信息需要在用户空间和内核空间相互拷贝的问题。

epoll并不是像select一样去遍历事件列表，然后逐个轮询的监控fd的事件状态，而是**事先就建立了fd与之对应的回调函数，当事件激活后主动回调callback函数**，这也就避免了遍历事件列表的这个操作，所以epoll并不会像select和poll一样随着监控的fd变多而效率降低。



**比较表格**

|              | select                                                       | poll                                                         | epoll                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |
| 性能         | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能基本没有变化                |
| 连接数       | 一般1024                                                     | 无限制                                                       | 无限制                                            |
| 内存拷贝     | 每次调用select拷贝                                           | 每次调用poll拷贝                                             | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 数据结构     |                                                              |                                                              | 红黑树                                            |
| 内在处理机制 | 线性轮询                                                     | 线性轮询                                                     | FD挂在红黑树，通过事件回调callback                |
| 时间复杂度   | O(n)                                                         | O(n)                                                         | O(1)                                              |



#### 有了解epoll吗？可以说说吗？

<font color=grey>epoll_create 创建一个 epoll对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</font>

（流程详见上面的4点。）

优势：

1. epoll 在内核里使用红黑树来跟踪进程所有待检测的fd，把需要监控的 socket 通过 `epoll_ctl()` 函数加入内核中的红黑树里，增删改一般时间复杂度是 `O(logn)`。select/poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。
2. epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 `epoll_wait()` 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select/poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h851wwaetlj30xb0fdwfr.jpg" alt="截屏2022-11-14 23.01.15" style="zoom: 50%;" />

epoll 支持两种事件触发模式，分别是边缘触发（edge-triggered，ET）和水平触发（level-triggered，LT）。

- 边缘触发模式，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次
- 水平触发模式，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；



#### ⚠️select poll 和 epoll 最大的差别是什么

select 和 poll 每次都需要两次复制、两次遍历。

epoll 仅在第一次创建红黑树，后续都是对红黑树进行管理，增删改时间复杂度 O(logn)，减少了拷贝和内存分配；事件驱动，维护活跃事件队列，只将有事件发生的 Socket 集合传递给应用程序。



#### ⚠️操作系统的 IO 模型(阻塞，非阻塞，IO多路复用，信号驱动IO，异步IO)



#### ⚠️一次普通 IO 的过程，什么时候用到了系统调用



#### 介绍下 IO 多路复用

最基础的 TCP 的 Socket 编程，它是阻塞 I/O 模型，基本上只能一对一通信，那为了服务更多的客户端，我们需要改进网络 I/O 模型。

传统的方式是使用多进程/线程模型，每来一个客户端连接，就分配一个进程/线程，后续的读写都在对应的进程/线程。但是当随着客户端数量的增长，大量的进程/线程的调度、上下文切换以及它们占用的内存，都会成为瓶颈。

为了解决上面这个问题，就出现了 I/O 的多路复用，可以只在一个进程里处理多个文件的 I/O，Linux 下有三种提供 I/O 多路复用的 API，分别是：select、poll、epoll。

再继续介绍 select、poll、epoll ...







## Linux

**查看socket**

可以使用 `netstat` 或者 `ss`，这两个命令查看 socket、网络协议栈、网口以及路由表的信息。

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h852p02lgej30k907rq3q.jpg" alt="截屏2022-11-14 23.28.18" style="zoom: 67%;" />

socket 的状态（*State*）、接收队列（*Recv-Q*）、发送队列（*Send-Q*）、本地地址（*Local Address*）、远端地址（*Foreign Address*）、进程 PID 和进程名称（*PID/Program name*）等。

当 socket 状态处于 `Established`时：

- *Recv-Q* 表示 socket 缓冲区中还没有被应用程序读取的字节数；
- *Send-Q* 表示 socket 缓冲区中还没有被远端主机确认的字节数；

而当 socket 状态处于 `Listen` 时：

- *Recv-Q* 表示全连接队列的长度；
- *Send-Q* 表示全连接队列的最大长度

在 TCP 三次握手过程中，当服务器收到客户端的 SYN 包后，内核会把该连接存储到半连接队列，然后再向客户端发送 SYN+ACK 包，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，内核会把连接从半连接队列移除，然后<font color=red>创建新的完全的连接，并将其增加到全连接队列</font> ，等待进程调用 `accept()` 函数时把连接取出来。



**查看协议栈**

TCP显示了主动连接（*active connections openings*）、被动连接（*passive connection openings*）、失败重试（*failed connection attempts*）、发送（*segments send out*）和接收（*segments received*）的分段数量等各种信息

<img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h852tzj6cpj30ih0nygol.jpg" alt="截屏2022-11-14 23.33.05" style="zoom:33%;" />





#### ⚠️Linux如何查看哪些端口建立tcp连接？这些端口都有哪些状态？为什么要有time-wait？

`netstat` 或者 `ss`

(listien,established,time-wait等等)。

状态：ESTABLISHED, CLOSE_WAIT, SYN_SENT, FIN_WAIT, TIME_WAIT 等等







#### 敲kill -9命令发生了什么。-9是什么意思

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 `SIGKILL` 信号，用来立即结束该进程；



## 待分类

操作系统的临界区了解吗



大端和小端有什么区别？



用户态和内核态



read 在三者中是用户发起还是内核发起？(用户发起)







# 计算机网络

## 通用

### ⚠️OSI七层模型【3】和五层模型？

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxkih9fn8pj313q0ja0wd.jpg" alt="截屏2021-12-20 19.14.11" style="zoom:33%;" />





**五层模型**

- 应用层：应用层是网络协议的最高层，主要任务**通过进程间的交互完成特定网络应用**。应用层协议定义的是 **应用程序（进程）间通信和交互的规则**。

  应用层协议有 HTTP、FTP、Telnet、DNS、SMTP等。应用层交互的数据单元称为 **报文**。

- 传输层：它负责**为两台主机中的进程提供通信服务**。该层主要有以下两种协议：

- - 传输控制协议 (Transmission Control Protocol，TCP)：提供**面向连接的、可靠的**数据传输服务，数据传输的基本单位是报文段（segment）；拥有流量控制、超时重传、拥塞控制等特性。
  - 用户数据报协议 (User Datagram Protocol，UDP)：提供**无连接的、尽最大努力的**数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。

- 网络层：网络层负责**为分组网络中的不同主机提供通信服务**，**并通过选择合适的路由将数据传递到目标主机**。在发送数据时，网络层把运输层产生的报文段或用户数据封装成 **分组** 或 包 进行传送。在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫 **IP数据报**。

  IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。

- 数据链路层：数据链路层通常简称为 链路层。数据链路层在两个相邻节点传输数据时，**将网络层交下来的IP数据报组装成帧，在两个相邻节点之间的链路上传送 帧。**

- 物理层：保证数据可以在各种物理媒介上进行传输，**为数据的传输提供可靠的环境**。



**TCP/IP的体系结构**

应用层、传输层、网络层..

网络接口层：在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。MAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。

网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。





#### 802.3x 工作在几层，为什么





## http

### http

#### ⚠️浏览器输入url到页面显示的过程【4】

1. 输入url

2. DNS解析（解析过程见下一节）

   查询的两种方式：递归和迭代

3. 建立TCP连接

4. 客户端发送HTTP报文

5. 服务器处理请求

6. 服务器响应请求，返回HTTP报文

7. 浏览器展示HTML

8. 浏览器发送请求获取其他在HTML中的资源





#### 分别介绍 http 1.1 2.0 3.0







#### http 状态码

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/6-%E4%BA%94%E5%A4%A7%E7%B1%BBHTTP%E7%8A%B6%E6%80%81%E7%A0%81.png" alt=" 五大类 HTTP 状态码 " style="zoom:50%;" />

`1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

`2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

- 「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
- 「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。
- 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

`3xx` 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

- 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。
- 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

- 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

`4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

- 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
- 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
- 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

`5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

- 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
- 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
- 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
- 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思





#### get和post请求的区别【2】





#### http 报文介绍



#### http 报文头和报文体分隔符是什么？\r\n 是什么意思(回车+换行)







### https

#### https的过程【2】



  



#### 每次请求，https 的公私钥固定不变吗？

(第一次会协商和加密，之后同一个浏览器的话会用 session id 做 session key 的提取，可以看做固定不变)



#### https 在传输消息前多出了几次 RTT(2-7次)



#### http和https的区别【3】

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- 两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。



**HTTPS 解决了 HTTP 的哪些问题？**

HTTP 由于是明文传输，所以安全上存在以下三个风险：

- **窃听风险**，比如通信链路上可以获取通信内容
- **篡改风险**，比如强制植入垃圾广告，视觉污染
- **冒充风险**，比如冒充淘宝网站

HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议，可以很好的解决了上述的风险：

- **信息加密**：交互信息无法被窃取
- **校验机制**：无法篡改通信内容，篡改了就不能正常显示
- **身份证书**：证明淘宝是真的淘宝网



**HTTPS 是如何解决上面的三个风险的？**

- **混合加密**的方式实现信息的**机密性**，解决了窃听的风险。

  对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。

  用摘要算法（哈希函数）来计算出内容的哈希值。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85wr6n56mj30mp0ar74w.jpg" alt="截屏2022-11-15 16.48.20" style="zoom: 50%;" />

- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

  权威的机构就是 CA （数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

  <img src="https://tva1.sinaimg.cn/large/008vxvgGgy1h85wu9kcczj30mw0g8tao.jpg" alt="截屏2022-11-15 16.51.19" style="zoom:50%;" />

（加密我就不写了）







## DNS

#### DNS解析过程

1. 解析域名，浏览器查看（浏览器）缓存，再**查看 hosts 文件**，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。

2. 如果在本地的 hosts 文件没有对应的 ip 地址，浏览器会**发出一个 DNS请求到本地DNS服务器** 。

3. 查询的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先**查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归**的方式进行查询。如果没有，本地DNS服务器还要**向DNS根服务器进行查询**。

4. 根DNS服务器没有记录具体的域名和IP地址的对应关系，而是**告诉本地DNS服务器，你可以到顶级域名服务器上去继续查询**，并给出顶级域名服务器的地址。这种过程是迭代的过程。

5. 本地DNS服务器继续向顶级域名服务器发出请求，在这个例子中，请求的对象是.com顶级域名服务器。.com顶级域名服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是**告诉本地DNS服务器，你的域名的权威域名服务器的地址**。

6. 最后，本地DNS服务器向对应的权威域名服务器发出请求，这时就能收到一个域名和IP地址对应关系，**本地DNS服务器不仅要把IP地址返回给用户电脑**，还要把这个**对应关系保存在缓存中**，以备下次别的用户查询时，可以直接返回结果，加快网络访问。





## TCP/UDP

tcp与udp的区别【2】



tcp为什么安全



tcp的超时重传机制



### 三次握手 四次挥手



#### TCP三次握手、四次挥手，timewait，closewait状态【4】



#### 为什么需要第四次挥手【3】





了解socket编程吗，【2】其中accept方法是什么



生成 tcp 和 udp socket有什么区别(在创建声明和 api 使用上均有区别)



socket 如何标识一个协议(sock_type)



tcp 和 udp 报文的区别(序号，确认号，数据偏移，标识符，窗口大小等)



如何设计一种机制在UDP上实现可靠传输？（确认和重传机制）补充？



tcp 可靠性，然后问十六位校验和怎么实现的



tcp 粘包【2】



TCP SYN 攻击



## 待分类



2MSL 的目的



不同协议能否监听同一个端口(可以)



为什么需要 非对称加密 和 对称加密



# 数据库

## Mysql

mysql的索引用的什么数据结构 ｜ mysql的索引底层是什么，除了B+树以外还有什么数据结构可以作为索引【3】



mysql 索引为什么用B+树



mysql索引了解，原理是什么？



Mysql的底层实现【2】



了解Mysql的悲观锁和乐观锁吗？简单介绍一下【2】





最左匹配原则。 怎么建立索引（我回答了最左匹配原则）【2】，面试官给了一个例子：查询一个student表，如果where条件中有性别和姓氏，应该选择哪个字段作为索引



## Redis

redis有哪些数据类型【2】



为什么要用redis？有考虑过redis失效，也就是服务宕机的情况吗？



redis缓存击穿，缓存穿透，缓存雪崩



redis 持久化的方式(RDB, AOF)【2】



## 哈希

hashmap原理



哈希索引【2】hash说一下？hash为什么不能范围查找？减少Hash冲突的办法？



哈希和B+树查询数据的时间复杂度（答了哈希O(1)，B+树$O(log_{m}n)$其实就是树高



跳表怎么实现



哈希表怎么实现，讲哈希冲突的时候讲了开放寻址法、拉链法，然后问除了这两个还有其他方法吗（不知道



红黑树，立刻说我红黑树不熟悉，然后就问了一个：红黑树是不是二叉平衡树，回答是特殊的平衡树，然后讲红黑树性质就没了





## 通用

如果删除索引出现问题了导致锁表怎么办？



说一下MVCC



覆盖索引和聚簇索引【2】



b + 树说一下？索引结构？



聚集索引和非聚集索引？



回表？怎么减少回表？回表出现错误怎么办



范围查找可以用索引嘛？（可以，但具体执行要看优化器如何优化）



连接操作join了解嘛？（左连接，右连接，内连接）



inner join连接操作怎么实现的？（大概讲了下流程，应该是问底层）



join的时间复杂度？（加索引和不加索引）



不加索引怎么优化连接操作？（大表在前，小表在后）还有嘛？（加缓存？不太确定）



LRU具体实现。（Hash和双向链表）



数据库binlog,redolog,undolog的区别。



底层硬盘宕掉怎么办



什么数据结构适合做索引，为什么适合做索引。（只说了B+树和hash，忘记了跳表。）





幻读是什么，解决方案



内部节点 和 叶子节点 满足一页数据页吗



主从同步（异步，半同步）





# 数据结构

红黑树和B+树的区别



B+树属于二叉树么



说一下拓扑排序



堆排序过程。时间复杂度。维护堆过程。堆中插入一个节点和删除一个节点的流程，时间空间复杂度。



你熟悉什么排序，各种排序的时间复杂度



堆排序建堆过程，建堆时间复杂度



需要几个栈实现一个队列，两个，口述压队出队



# Golang

## 通用

golang语言，它与其他语言的不同



函数传指针和传值有什么区别？



new和make有什么区别？



为什么Golang可以很容易实现高并发。



go的slice内部有什么？



go slice 和 array 区别



slice的扩容



make一个slice后返回的是指针吗？map呢？



一个函数传参一个slice，先append再赋值和另一个函数先赋值再append，哪个会发生变化？



go的map是线程安全的吗？



对象是什么。面向对象有什么好处。go的多态。





## 协程

golang中协程的概念，协程之间怎么通信



了解GMP模型吗，介绍一下？【2】



一组协程完成后需要通知其他协程，可以怎么办？（管道？）







## 管道

channel了解吗，channel的工作原理是什么？

向一个已经关闭的channel发送数据，会发生什么；从一个已经关闭的channel中接收数据，会发生什么



## GC

golang的GC【2】



三色标记法的灰色、黑色有什么区别？为什么区分灰色和黑色，灰色存在的意义？



写屏障是什么？





什么是内存逃逸，在什么情况下发生，原理是什么?





## 框架

Gin框架的中间件是怎么实现的？有了解吗？



Gin框架吧，为什么使用Gin框架？可以大概说一下Gin框架的具体实现吗？



Gin框架的路由树的实现。







# 通用

如果要设计一个秒杀系统，需要加锁？加到哪一层？代码？数据库？网关



有了解过微服务的基本原理吗？



微服务是怎么实现鉴别不同的服务的？



了解IO多路复用吗？可以说说大致的实现吗？



介绍下 jwt



# 算法题

最大岛屿数量



反转一个带符号的整数：-32变为-23.整数在[-2^31, 2^31-1]之间；需要注意输入数据的类型和是否结果会溢出



分苹果



求一个数组的所有可能的元素集合



二叉树中序遍历 



返回一个大数的阶乘结果，输入为字符串，输出也为字符串



二叉树转双向链表。



LC 394 字符串解码



 最长连续序列



有n个"("和")"，输出所有的排列组合



根节点到叶子节点路径和为目标值的路径



口述链表是否存在环。数学证明。过渡到如果快指针一次走三步行不行。【2】



一个数组，元素从两边到中间单调递增，找出元素种类的个数。[4,5,6,9,7,6,5,1] 结果应该返回6。面试的话应该空间复杂度O(1)才能通过（双指针？）



接雨水



删除链表中的重复元素2



字典序的第K小数字



去除链表中重复元素



最长的格式正确的括号字符串



输入 n，给出 1~n 的所有排列，不要求输出有序

即 输入 3，输出 1，2，3，12，13，23，123





# 智力题

烧绳子，接水。



32个球，重量都不一样，只有一个天平，需要多少次才能找到最终的？需要多少次才能找到第二重的？



# 场景题

设计一个邀请码，数字字母组成，固定长度，唯一，邀请码之间变化比较大。考虑了半天，说了个错误的。8会，想了解的同学可以参考base62编码规则。



两个大文件找重复行