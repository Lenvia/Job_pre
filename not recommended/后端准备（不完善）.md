[TOC]

## 操作系统

### 进程和线程，以及协程

#### 区别

最主要差别在于它们是不同的操作系统资源管理方式

- 进程是系统进行**资源分配和调度的一个独立单位**，有独立的地址空间。线程是**CPU调度和分配的基本单位**，线程有自己的**堆栈**和**局部变量**，但线程之间没有单独的地址空间，多个线程共享进程所拥有的资源。
- 进程切换时耗费资源较大，线程之间切换开销小。



#### 联系

- 一个程序至少有一个进程，一个进程至少有一个线程



协程是一种比线程更轻量级的微线程



### 线程继承进程的哪些资源

代码区：编译后的可执行机器指令

堆区：存储new 或者 malloc出来的数据。只要知道变量的地址，任何一个线程都可以访问指针指向的数据。

文件：如果程序在运行过程中打开了一些文件，那么进程地址空间中还保存有打开的文件信息，进程打开的文件也可以被所有的线程使用



### 进程调度算法

先来先服务（FCFS）、短作业优先（SJF）、时间片轮转、多级反馈队列、高响应比优先

#### 先来先服务

先来的程序先被调度。但是缺点是，如果执行一个长作业，那后面的短作业就会被长时间搁置

#### 短作业优先

优先把短作业执行完，再执行长作业。缺点是如果短作业很多，长作业会被搁置。

#### 时间片轮转

定义一个时间片长度，平均给每个进程分配时间片，一旦时间片用完，作业就会由进行转为就绪，等待重新被调度。缺点是如果作业比较多，那长作业可能需要好几轮才可以被执行完。

#### 多级反馈队列

设置了不同的队列，可以分类为高、中、低优先级。优先级越高，分配的时间片越小。首先刚来的会进入高优先级，如果没执行完进入下一级的优先级。只有上一个队列执行完后，才可以开始下一个队列。缺点还是长作业的问题，加入上一级队列一直有作业，那下一级别的队列的进程就会饥饿

#### 高响应比优先

是在短作业优先的基础上改进，加上一个随时间叠加的权重。等待时间越长，权重越高。

这种算法既可以优先完成短作业，又能确保长作业不会长期饥饿。



### 进程间的通信方式

管道、消息队列、共享内存、信号量、套接字

#### 管道

单向的传输，A进程将数据以字节流写入管道，B进程需要等待A进程将信息写完以后才能读出来。

比如 ps -f | grep xxx

#### 消息队列

在发送数据时，按照一个个独立单元发送，发送方和接收方约定好消息的类型和格式

缺点：数据太大时，需要拷贝的时间多

#### 共享内存

申请一块虚拟地址空间，不同进程通过这块虚拟地址空间映射到相同的物理地址空间。就不需要再拷贝来拷贝去了

缺点：会出现冲突

#### 信号量

防止冲突的一个约束和保护机制。

定义p操作和v操作。p操作为申请资源，v操作是归还资源。

#### 信号

每个信号设置相应的函数，一旦进程发送某一个信号给另一个进程，另一进程将执行相应的函数进行处理。

#### 套接字

联网情况下



### 什么是死锁、产生条件、如何解决

死锁：两个或两个以上线程都在等待对方执行完毕才能继续往下执行的时候，就会发生死锁。结果就是这些线程陷入了无尽的等待。

四个必要条件：

1. 互斥条件：一个资源只能被一个进程所使用
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放
3. 不可抢占条件：进程已获得的资源，在未使用完之前，不能强行剥夺
4. 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源的关系



如何解决？

（互斥不可破坏）

（不可抢占条件破坏代价大，实现复杂）

破坏请求与保持条件：允许进程获取初期所有资源后，便开始运行，运行过程中再逐步释放自己占有的资源

破坏循环与等待条件：对各进程请求资源的顺序做一个规定，避免相互等待









### Linux进程管理命令

ps、pstree、top、htop、nice、renice、kill、ulimit、w





### select, poll, epoll

https://zhuanlan.zhihu.com/p/367591714

https://zhuanlan.zhihu.com/p/126278747



select，poll，epoll都是IO多路复用机制，即可以监视多个描述符，一旦某个描述符就绪（读或写就绪），能够通知程序进行相应读写操作。

(fd：文件描述符)

#### select

1. 在调用select之前告诉select 应用进程需要监控哪些fd可读、可写、异常事件，这些分别都存在一个fd_set数组中。
2. 应用进程调用select的时候把3个fd_set传给内核（产生了一次fd_set在用户空间到内核空间的复制），内核收到fd_set后对fd_set进行遍历，然后一个个去扫描对应fd是否满足可读写事件。
3. 如果发现了有对应的fd有读写事件后，内核会把fd_set里没有事件状态的fd句柄清除，然后把有事件的fd返回给应用进程（这里又会把fd_set从内核空间复制用户空间）。
4. 最后应用进程收到了select返回的活跃事件类型的fd句柄后，再向对应的fd发起数据读取或者写入数据操作。



缺陷：

1. 每次调用select，都需要把**被监控的fds集合从用户态空间拷贝到内核态空间**，高并发场景下这样的拷贝会使得消耗的资源是很大的。
2. **能监听端口的数量有限**，单个进程所能打开的最大连接数有FD_SETSIZE宏定义
3. 被监控的fds集合中，**只要有一个有数据可读，整个socket集合就会被遍历一次收集可读事件**：仅仅关心是否有数据可读这样一个事件







#### epoll

1. 创建内核事件表（epoll_create）。

   向内核申请创建一个fd的文件描述符作为内核事件表（B+树结构的文件，没有数量限制），这个描述符用来保存应用进程需要监控哪些fd和对应类型的事件。

2. 添加或移出监控的fd和事件类型（epoll_ctl）

   调用此方法可以是向内核的内核事件表 动态的添加和移出fd 和对应事件类型

3. epoll_wait 绑定回调事件

   内核向事件表的fd绑定一个回调函数。

   当监控的fd活跃时，会调用callback函数把事件加到一个活跃事件队列里;

4. 最后在epoll_wait 返回的时候内核会把活跃事件队列里的fd和事件类型返回给应用进程。





#### 比较表格

|              | select                                                       | poll                                                         | epoll                                             |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------- |
| 性能         | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能急剧下降，处理成千上万的并发连接数时，性能很差 | 随着连接数的增加，性能基本没有变化                |
| 连接数       | 一般1024                                                     | 无限制                                                       | 无限制                                            |
| 内存拷贝     | 每次调用select拷贝                                           | 每次调用poll拷贝                                             | fd首次调用epoll_ctl拷贝，每次调用epoll_wait不拷贝 |
| 数据结构     |                                                              |                                                              | 红黑树                                            |
| 内在处理机制 | 线性轮询                                                     | 线性轮询                                                     | FD挂在红黑树，通过事件回调callback                |
| 时间复杂度   | O(n)                                                         | O(n)                                                         | O(1)                                              |



## 计算机网络

### 五层结构

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxkih9fn8pj313q0ja0wd.jpg" alt="截屏2021-12-20 19.14.11" style="zoom:33%;" />

- 应用层：应用层是网络协议的最高层，主要任务**通过进程间的交互完成特定网络应用**。应用层协议定义的是 **应用程序（进程）间通信和交互的规则**。

  应用层协议很多，如域名系统DNS，支持万维网应用的HTTP协议，支持电子邮件的SMTP协议，等等。应用层交互的数据单元称为 **报文**。

- 运输层：它负责**为两台主机中的进程提供通信服务**。该层主要有以下两种协议：

- - 传输控制协议 (Transmission Control Protocol，TCP)：提供**面向连接的、可靠的**数据传输服务，数据传输的基本单位是报文段（segment）；
  - 用户数据报协议 (User Datagram Protocol，UDP)：提供**无连接的、尽最大努力的**数据传输服务，但不保证数据传输的可靠性，数据传输的基本单位是用户数据报。

- 网络层：网络层负责**为分组网络中的不同主机提供通信服务**，**并通过选择合适的路由将数据传递到目标主机**。在发送数据时，网络层把运输层产生的报文段或用户数据封装成 **分组** 或 包 进行传送。

  在TCP/IP体系中，由于网络层使用IP协议，因此分组也叫 **IP数据报**。

- 数据链路层：数据链路层通常简称为 链路层。数据链路层在两个相邻节点传输数据时，**将网络层交下来的IP数据报组装成帧，在两个相邻节点之间的链路上传送 帧。**

- 物理层：保证数据可以在各种物理媒介上进行传输，**为数据的传输提供可靠的环境**。



### 地址解析协议(ARP)

<font color=blue>ARP: 知道下一跳IP地址，查询其MAC地址</font>

- 每个路由器/主机中都有一个ARP缓存(Cache)
  - 存储局域网内各主机或路由器的地址映射关系
- 节点A向局域网内另一节点B发送IP报文
  - 如果ARP Cache中有对应条目，将该MAC地址作为目的地址发送数据帧
  - 否则，A向局域网内广播ARP请求，询问节点B的IP地址对应的MAC地址
    - B收到该请求后，回复自己的MAC地址
    - A和B都会将对方地址的映射关系写入ARP Cache

注意: ARP协议**只作用于局域网**，两节点IP不在同一网段时，数据报文应先转发到路由器











### 三次握手四次挥手 (TCP的连接和释放)

#### 三次握手

1. 主机A向主机B发送TCP连接请求数据包，包含A的初始序列号seq(A) = x
2. 主机B收到请求后，发送连接确认数据包。ack设置为A的序列号+1。B的序列号也包含在内，设为y
3. 主机A收到主机B的确认报文，还需再做出确认，发送一个包含序列号为x+1，ack设置为y+1

<img src="/Users/yy/Library/Application Support/typora-user-images/截屏2021-12-15 15.34.54.png" alt="截屏2021-12-15 15.34.54" style="zoom: 33%;" />



#### 四次挥手

假设主机A为客户端，主机B为服务器

1. 关闭客户端到服务器的连接：客户端A发送一个FIN，用来关闭客户端到服务器的数据传送，然后等待服务器的确认。终止标识为FIN = 1，序列号为u
2. 服务器收到这个FIN，发回一个ACK，ack为收到的序号+1
3. 关闭服务器到客户端的连接：也是发送一个FIN给客户端
4. 客户端收到FIN后，发回一个ACK报文确认，将ack设置为收到的序号+1.

首先关闭的一方将执行主动关闭，而另一方执行被动关闭。

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxekcoh4ldj313m0rcdkk.jpg" alt="截屏2021-12-15 15.45.38" style="zoom:33%;" />



#### 为什么是三次握手？

为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。

“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。

假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”。主要目的防止server端一直等待，浪费资源。



#### 为什么是四次挥手？

关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。



### TCP如何实现流量控制

由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。

主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，根据接收窗口大小，控制发送方的发送窗口大小，发送方发送窗口内的数据全部发送后，在没有收到ACK确认报文，不会发送新的数据。丢失的数据包会超时重传，发送方收到零窗口通知时会启动持续计时器，超时后会发送零窗口探测报文，以次获取接收方的窗口值大小，保证数据传输。





### TCP如何实现拥塞控制

四种算法：慢启动、拥塞避免、快速重传、快速恢复

发送方维持一个叫做拥塞窗口cwnd(congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。

为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个**慢开始门限 ssthresh**。

#### 慢启动

使用慢启动算法后，每经过一轮传输，拥塞窗口cwnd就加倍。

当拥塞窗口大小达到门限时，开始改用拥塞避免算法



#### 拥塞避免

让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1（报文段的个数）。

当发生拥塞时，更新门限值为当前的一半。并开始执行慢启动。



#### 快速重传

快重传要求**接收方**在收到一个失序的报文段后就立即发出重复确认，而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期



#### 快速恢复

当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把ssthresh门限减半（为了预防网络发生拥塞）。但是接下去并不执行慢启动算法，而是将拥塞窗口大小设置为ssthresh减半后的值，然后执行拥塞避免算法，使cwnd缓慢增大。



### 输入url到页面展示，经历了哪些过程

1. 输入url

2. DNS解析

   查询的两种方式：递归和迭代

3. 建立TCP连接

4. 客户端发送HTTP报文

5. 服务器处理请求

6. 服务器响应请求，返回HTTP报文

7. 浏览器展示HTML

8. 浏览器发送请求获取其他在HTML中的资源



### DNS 解析的过程

1. 请求一旦发起，浏览器首先要做的事情就是解析这个域名，一般来说，浏览器会首先**查看 hosts 文件**，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。

2. 如果在本地的 hosts 文件没有对应的 ip 地址，浏览器会**发出一个 DNS请求到本地DNS服务器** 。

3. 查询的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先**查询它的缓存记录**，如果缓存中有此条记录，就可以直接返回结果，此过程是**递归**的方式进行查询。如果没有，本地DNS服务器还要**向DNS根服务器进行查询**。

4. 根DNS服务器没有记录具体的域名和IP地址的对应关系，而是**告诉本地DNS服务器，你可以到顶级域名服务器上去继续查询**，并给出顶级域名服务器的地址。这种过程是迭代的过程。

5. 本地DNS服务器继续向顶级域名服务器发出请求，在这个例子中，请求的对象是.com顶级域名服务器。.com顶级域名服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是**告诉本地DNS服务器，你的域名的权威域名服务器的地址**。

6. 最后，本地DNS服务器向对应的权威域名服务器发出请求，这时就能收到一个域名和IP地址对应关系，**本地DNS服务器不仅要把IP地址返回给用户电脑**，还要把这个**对应关系保存在缓存中**，以备下次别的用户查询时，可以直接返回结果，加快网络访问。



## 数据库

### 数据库的隔离级别以及实现 

| 隔离级别 | 脏读   | 不可重复读 | 幻读   | 实现原理                                                     |
| -------- | ------ | ---------- | ------ | ------------------------------------------------------------ |
| 未提交读 | 可能   | 可能       | 可能   | 读数据不加锁，修改数据加行级共享锁                           |
| 已提交读 | 不可能 | 可能       | 可能   | 读取时增加行级共享锁，一旦读完立即释放；更新瞬间加行级排他锁，直至事务结束才释放 |
| 可重复读 | 不可能 | 不可能     | 可能   | 读取瞬间增加行级共享锁，直到事务结束才释放；更新瞬间增加行级排他锁，直至事务结束才释放 |
| 可串行化 | 不可能 | 不可能     | 不可能 | 读取瞬间增加表级共享锁，直到事务结束才释放；更新瞬间增加表级排他锁，直至事务结束才释放 |

未提交读：允许脏读，也就是可能会读到其他会话中未提交事务修改的数据。

提交读：只能读到已提交的数据。（Oracle等多数据库默认级别）

可重复读：可重复度。在同一个事务内的查询都是事务开始时刻一致的。（InnoDB默认级别。在SQL标准中，该隔离级别消除了不可重复度，但是还存在幻读）

可串行化：完全串行化的读，每次读都需要获得表级共享锁，读写相互都会阻塞。







## 项目

### SpringMVC的执行流程

<img src="https://tva1.sinaimg.cn/large/008i3skNly1gxfoegtbtzj31fs0q479n.jpg" alt="截屏2021-12-16 14.51.18" style="zoom:50%;" />

1. 用户发送请求至前端控制器DispatcherServlet。
2. DispatcherServlet收到请求调用HandlerMapping处理器映射器。
3. 处理器映射器找到具体的处理器(可以根据xml配置、注解进行查找)，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。
4. DispatcherServlet调用HandlerAdapter处理器适配器。
5. HandlerAdapter经过适配调用具体的处理器(Controller，也叫后端控制器)。
6. Controller执行完成返回ModelAndView。
7. HandlerAdapter将controller执行结果ModelAndView返回给DispatcherServlet。
8. DispatcherServlet将ModelAndView传给ViewReslover视图解析器。
9. ViewReslover解析后返回具体View。
10. DispatcherServlet根据View进行渲染视图（即将模型数据填充至视图中）。DispatcherServlet响应用户。





### IOC和AOP

1.IOC
许多应用都是通过彼此间的相互合作来实现业务逻辑的，如类A要调用类B的方法，以前我们都是在类A中，通过自身new一个类B，然后在调用类B的方法，现在我们把new类B的事情交给spring来做，在我们调用的时候，容器会为我们实例化。

2. IOC容器的初始化过程
     资源定位，即定义bean的xml-------》载入--------》IOC容器注册，注册beanDefinition

    IOC容器的初始化过程，一般不包含bean的依赖注入的实现，在spring IOC设计中，bean的注册和依赖注入是两个过程，，依赖注入一般发生在应用第一次索取bean的时候，但是也可以在xm中配置，在容器初始化的时候，这个bean就完成了初始化。



3. 三种注入方式:构造方法注入，setter注入，基于注解的注入。我们常用的是基于注解的注入

4. bean是如何创建---  工厂模式

5. 数据是如何注入-------反射

6.AOP

    面向切面编程，在我们的应用中，经常需要做一些事情，但是这些事情与核心业务无关，比如，要记录所有update*方法的执行时间时间，操作人等等信息，记录到日志，

通过spring的AOP技术，就可以在不修改update*的代码的情况下完成该需求。

7.AOP的实现原理------代理





#### Django后端

后端使用 Django 框架，配合Pytorch，使用已经训练好的模型提供摘要结果。

前后端交互逻辑主要分成n个文件：`urls.py` 和 `views.py`。由于该任务无需使用数据库，只是对后端收到的文本进行摘要提取并返回，这些工作可以在 MVC 机制中的视图层完成。

首先设定 Django 的路由，我们想要在本地启动服务器并通过指定前缀访问（即 http:121.0.0.1/abstract/），于是在 `urls.py` 中进行如下配置：

`/abstract/urls.py` 中绑定路由和页面

```
app_name = 'abstract'
urlpatterns = [
    path('', views.index, name='index'),
]
```

`/nlpsite/urls.py` 对以上配置进行引入

```
urlpatterns = [
    path('', include('abstract.urls')),
]
```

之后，我们希望在第一次启动服务器的加载模型，每次接收到来自前端页面的 request 请求，只需调用已加载的模型即可。

`/abstract/views.py` 的顶部添加加载模型的代码，并定义 def index(request) 函数（函数名与urls.py 中的 name 保持一致）

- 若来自于 ajax 发送的请求，且方法为 POST ，则读取数据并处理，将结果放入 json 文件并封装到 HttpResponse 返回
- 返回静态页面



其它需要的 CSS, JS 与数据文件在 `static/` 目录下，主页的 HTML 在 `templates/` 目录下。





