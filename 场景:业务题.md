[TOC]



# 智力题

全都在下面的链接：

https://blog.csdn.net/qq_46588810/article/details/122088043

https://blog.csdn.net/qq_29966203/article/details/124213450



**1.赛马找最快<腾讯高频>**

**2.砝码称轻重**

**3.药瓶毒白鼠<腾讯>**

**4.绳子两头烧**

**5.犯人猜颜色**

**6.猴子搬香蕉**

**7.高楼扔鸡蛋<谷歌>**

**8.轮流取石子<字节>**

**9.蚂蚁走树枝**

**10.海盗分金币<不常见>**

**11.三个火枪手**

**12.囚犯拿豆子**

**13.学生猜生日<笔试高频>**





# 场景题

### 设计邀请码
> 数字字母组成，固定长度，唯一，邀请码之间变化比较大。

加密算法/编码



设计一个秒杀系统，需要加锁？加到哪一层？代码？数据库？网关

```
库存数量：在秒杀系统中，库存数量是最关键的数据之一。需要在减少库存数量的代码块中添加锁机制，避免多个线程同时减少库存数量导致数据不一致的问题。
用户请求：在秒杀系统中，用户请求是一个瓶颈，需要控制用户的请求速度和并发数量，避免服务器负载过高。可以通过添加限流措施（如令牌桶算法、漏桶算法等）控制用户请求的速度和数量。同时，也可以在用户请求的代码块中添加锁机制，避免多个线程同时处理同一个用户请求导致数据不一致的问题。
订单生成：在秒杀系统中，订单生成是最后的环节，也是最容易出问题的地方。需要在生成订单的代码块中添加锁机制，避免多个线程同时生成订单导致订单重复的问题。
加锁的具体实现方式有很多种，可以使用数据库锁、分布式锁、缓存锁等。一般来说，因为分布式锁和缓存锁的性能更好，更适合用于高并发的秒杀系统中。
```



### 大文件查询
一个文件里有一百亿条数据，该怎么处理和保存，使得能够快速找到想要的数据？

```
哈希到不同的桶里，对于每个桶，可以进行排序。

如果每个桶里的数据还是很大，那就分治，例如分成10块，对每一块分别排序。

寻找阶段：哈希值得到桶 -> 对于每个块 顺序/二分查找（当前块没有就继续下一个块）
```



### 两个大文件找重复行

```
具体步骤如下：
遍历第一个文件，对每一行进行哈希运算，将哈希值作为键，将行号（或行内容）作为值存入哈希表中。
遍历第二个文件，对每一行进行哈希运算，查找哈希表中是否已存在该哈希值，如果存在，则说明这一行与第一个文件中的某一行重复，记录下重复的行号（或行内容）。
当遍历完第二个文件后，所有重复的行号（或行内容）都已经记录下来了。
需要注意的是，由于文件较大，不能一次性将整个文件读入内存中处理，可以采用分块读取的方式，将文件分成若干个块，每次读取一个块进行处理，以减小内存的使用量。
此外，为了提高查找速度，可以使用一些哈希算法和哈希表实现方案，如Rabin-Karp哈希算法和布隆过滤器等，以提高查找的效率和减小哈希表的空间占用。
```



### 维护热搜

https://www.zhihu.com/question/57968453

小规模：最大堆



百万级：

1. **采样**：比如抽1/100变成几万个
2. **近似算法**：
   - 使用如HyperLogLog、Count-Min Sketch等近似算法来统计数据。这些算法可以在有限的内存中估计大数据集的统计信息。
   - 为每个话题创建一个 HyperLogLog。当用户访问或提及一个话题时，将用户的唯一标识符（如用户ID）添加到该话题对应的 HLL 中。定期（例如每小时或每天）评估每个话题的 HLL 以估计其唯一访问者数量。



### 曝光系统

> 从后端的角度如何设计一个曝光接口？ 例如，用户（通过用户id标识）看过的文章（通过文章id标识），曝光系统接收所有的文章列表和用户信息，返回三天内用户没有看过的文章id。 从表的设计、曝光的机制等来讲解

设计一个曝光接口需要考虑多个方面，包括数据存储、查询效率、数据时效性和系统的可扩展性。以下是从后端的角度设计这样一个接口的建议：

1. **数据库表设计**:
   - **用户表** (`users`):
     - `user_id`: 用户的唯一标识。
     - 其他用户相关信息。
   - **文章表** (`articles`):
     - `article_id`: 文章的唯一标识。
     - 其他文章相关信息。
   - **曝光表** (`exposures`):
     - `exposure_id`: 曝光的唯一标识。
     - `user_id`: 用户ID。
     - `article_id`: 文章ID。
     - `exposure_timestamp`: 曝光的时间戳。
2. **曝光机制**:
   - 每当用户查看一个文章列表，后端会记录这些文章的 `article_id` 和用户的 `user_id` 到 `exposures` 表中，同时记录当前的时间戳。
3. **查询未曝光的文章**:
   - 当需要查询三天内用户没有看过的文章时，首先从 `exposures` 表中查询三天内该用户的所有曝光记录。
   - 使用这些曝光记录的 `article_id`，从 `articles` 表中查询用户未曝光的文章。
4. **性能优化**:
   - 为 `exposures` 表中的 `user_id` 和 `exposure_timestamp` 创建索引，以加速查询。
   - 考虑使用缓存系统，如 Redis，来缓存用户的最近曝光记录，从而减少对数据库的查询。
5. **数据清理**:
   - 由于只关心三天内的曝光记录，可以定期清理 `exposures` 表中超过三天的旧记录，以节省存储空间。
6. **可扩展性**:
   - 如果曝光数据量非常大，可以考虑使用分布式数据库或分片技术来存储数据。
   - 可以使用负载均衡器来分发API请求，确保系统可以处理大量的并发请求。

通过上述设计，后端可以有效地处理用户的曝光数据，快速查询三天内用户未曝光的文章，并确保系统的性能和可扩展性。



**如何解决上面存储上限问题？**

**定时任务**:

- 使用如 `cron`（在Unix-like系统上）来定期执行一个清理任务。

- 例如，你可以每天凌晨执行一个SQL命令来删除旧记录。

  ```sql
  DELETE FROM exposures WHERE exposure_timestamp < NOW() - INTERVAL 3 DAY;
  ```

**分区**:

- 对于非常大的表，你可以考虑使用分区技术。例如，你可以根据日期对表进行分区，每天创建一个新的分区。然后，你只需要定期删除整个超过三天的分区，而不是删除单个记录。这通常比删除单个记录更快。







视频编码解码

工程处理视频的工具

AI可以在视频做什么