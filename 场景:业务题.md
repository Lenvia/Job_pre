[TOC]



# 智力题

详见下面的链接：

https://blog.csdn.net/qq_46588810/article/details/122088043

https://blog.csdn.net/qq_29966203/article/details/124213450



- 赛马找最快

- 砝码称轻重

- 药瓶毒白鼠
  - 二进制

- 绳子两头烧

- 犯人猜颜色
  - 奇偶

- 猴子搬香蕉
  - 临界值。把所有香蕉搬走1米需要吃掉3根，

- 高楼扔鸡蛋
  - 不完善但够用： x + h/x 的极值点

  - 最优法：(x+1)*x/2 = h

- 轮流取石子

- 蚂蚁走树枝【有多个变种，这里只收集了最简单的情况】

- 海盗分金币

- 三个火枪手
  - 博弈，从后往前推

- 囚犯拿豆子

- 学生猜生日

- 水王问题
  - 出现超过一半的，直接抵消
  - 【进阶】出现超过 1/n，每次抵消不同的n个





# 场景题

## 数据压缩

### 有 n 个数需要存储

**bitmap**：⽤⼀个位（bit）来标记某个数据的存放状态。第i位表示数值为i的元素是否存在。

优点：针对于稠密的数据集可以很好体现出位图法的优势，内存消耗少，速度较快

缺点：不适⽤于稀疏数据集



### 排序

> 假设有⼀个不重复的整型序列，已知最大值，实现排序

桶排序 + bitmap

1. 第⼀遍遍历整个序列，将出现的数字在bitmap中对应的位置置为1（如果含有重复数字，那么就自增）；
2. 第⼆遍遍历位图，依次输出值为1的位对应的数字







## TopK 问题

分治 + 小顶堆是关键

### n 个数找最大的k个

1. 先拿 k 个数建堆

2. 逐个添加剩余元素
3. 如果⼤于堆顶的数，将这个数替换堆顶，并调整结构使之仍然是⼀个最⼩堆
4. 遍历完后，堆中的k个数就是所需的最⼤的。

进一步优化：

【含有大量重复数据】hash去重

【提升速度】将数据划分成m个partition，每个partition交给⼀个最⼩堆（容量为k），可以断定最大的k个数一定在这 m*k 的数中，最后将结果归并。





### 维护热搜

> 有⼏台机器存储着⼏亿搜索日志，在资源有限的情况下，怎么选出搜索热度最⾼的⼗个？

> **针对top k文本问题，通常⽐较好的⽅案是【分治+hash/字典树+⼩顶堆】，即先将数据集按照hash⽅法分解成多个⼩数据集，统计每个⼩数据集中的query词频，之后⽤⼩顶堆求出每个数据集中出频率最⾼的前K个数，最后在所有top K中求出最终的top K。**



1. 拆分成n个⽂件：以⾸字母区分，不同⾸字母放在不同⽂件。就能保证数据被独⽴的分为了n个⽂件，且各个⽂件中不存在关键词的交集。
2. 分别词频统计：对于每个⽂件，使⽤hash或者Trie树进⾏进⾏词频统计
3. ⼩顶堆排序：依次处理每个⽂件，并逐渐更新最⼤的⼗个词



**采样或许也是一种优化策略**





## 系统设计

### 秒杀系统

应该考虑的问题：超卖、高并发、接口防刷、秒杀URL、数据库设计

设计方案：

- 数据库设计：最基础的两张表，一张是秒杀订单表，一张是秒杀货品表。其他的还可以加用户表等
- 秒杀URL：URL实现动态化，前端访问后台获取具体的URL，后台校验通过之后才可以继续秒杀。
- redis 集群
- nginx 负载均衡
- **接口限流**
  - 前端限流：发起请求后，接下来的一段时间内无法点击
  - 一段时间内重复请求直接拒绝，可以通过设置 redis 过期时间
  - 令牌桶算法：固定速度往一个桶内增加令牌，当桶内令牌满了后，就停止增加令牌。每个请求尝试获取一个令牌，后端只处理持有令牌的请求
- 异步下单：消息队列





### 曝光系统

> 从后端的角度如何设计一个曝光接口？ 例如，用户（通过用户id标识）看过的文章（通过文章id标识），曝光系统接收所有的文章列表和用户信息，返回三天内用户没有看过的文章id。 从表的设计、曝光的机制等来讲解

设计一个曝光接口需要考虑多个方面，包括数据存储、查询效率、数据时效性和系统的可扩展性。以下是从后端的角度设计这样一个接口的建议：

1. **数据库表设计**:
   - **用户表** (`users`):
     - `user_id`: 用户的唯一标识。
     - 其他用户相关信息。
   - **文章表** (`articles`):
     - `article_id`: 文章的唯一标识。
     - 其他文章相关信息。
   - **曝光表** (`exposures`):
     - `exposure_id`: 曝光的唯一标识。
     - `user_id`: 用户ID。
     - `article_id`: 文章ID。
     - `exposure_timestamp`: 曝光的时间戳。
2. **曝光机制**:
   - 每当用户查看一个文章列表，后端会记录这些文章的 `article_id` 和用户的 `user_id` 到 `exposures` 表中，同时记录当前的时间戳。
3. **查询未曝光的文章**:
   - 当需要查询三天内用户没有看过的文章时，首先从 `exposures` 表中查询三天内该用户的所有曝光记录。
   - 使用这些曝光记录的 `article_id`，从 `articles` 表中查询用户未曝光的文章。
4. **性能优化**:
   - 为 `exposures` 表中的 `user_id` 和 `exposure_timestamp` 创建索引，以加速查询。
   - 考虑使用缓存系统，如 Redis，来缓存用户的最近曝光记录，从而减少对数据库的查询。
5. **数据清理**:
   - 由于只关心三天内的曝光记录，可以定期清理 `exposures` 表中超过三天的旧记录，以节省存储空间。
6. **可扩展性**:
   - 如果曝光数据量非常大，可以考虑使用分布式数据库或分片技术来存储数据。
   - 可以使用负载均衡器来分发API请求，确保系统可以处理大量的并发请求。

通过上述设计，后端可以有效地处理用户的曝光数据，快速查询三天内用户未曝光的文章，并确保系统的性能和可扩展性。



**如何解决上面存储上限问题？**

**定时任务**:

- 使用如 `cron`（在Unix-like系统上）来定期执行一个清理任务。

- 例如，你可以每天凌晨执行一个SQL命令来删除旧记录。

  ```sql
  DELETE FROM exposures WHERE exposure_timestamp < NOW() - INTERVAL 3 DAY;
  ```

**分区**:

- 对于非常大的表，你可以考虑使用分区技术。例如，你可以根据日期对表进行分区，每天创建一个新的分区。然后，你只需要定期删除整个超过三天的分区，而不是删除单个记录。这通常比删除单个记录更快。





## 其他

### 设计邀请码

> 数字字母组成，固定长度，唯一，邀请码之间变化比较大。

加密算法/编码





### 大文件查询

> 一个文件里有一百亿条数据，该怎么处理和保存，使得能够快速找到想要的数据？

```
哈希到不同的桶里，对于每个桶，可以进行排序。

如果每个桶里的数据还是很大，那就分治，例如分成10块，对每一块分别排序。

寻找阶段：哈希值得到桶 -> 对于每个块 顺序/二分查找（当前块没有就继续下一个块）
```



### 两个大文件找重复行

```
遍历第一个文件，对每一行进行哈希运算，将哈希值作为键，将行号（或行内容）作为值存入哈希表中。
遍历第二个文件，对每一行进行哈希运算，查找哈希表中是否已存在该哈希值，如果存在，则说明这一行与第一个文件中的某一行重复，记录下重复的行号（或行内容）。
当遍历完第二个文件后，所有重复的行号（或行内容）都已经记录下来了。
需要注意的是，由于文件较大，不能一次性将整个文件读入内存中处理，可以采用分块读取的方式，将文件分成若干个块，每次读取一个块进行处理，以减小内存的使用量。
此外，为了提高查找速度，可以使用一些哈希算法和哈希表实现方案，如Rabin-Karp哈希算法和布隆过滤器等，以提高查找的效率和减小哈希表的空间占用。
```

